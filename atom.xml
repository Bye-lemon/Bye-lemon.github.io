<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Li.</title>
  
  
  <link href="http://bye-lemon.github.io/atom.xml" rel="self"/>
  
  <link href="http://bye-lemon.github.io/"/>
  <updated>2022-01-25T03:35:05.297Z</updated>
  <id>http://bye-lemon.github.io/</id>
  
  <author>
    <name>李英平</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>当我们落魄到需要去借别人的算力跑实验的时候</title>
    <link href="http://bye-lemon.github.io/post/be6/"/>
    <id>http://bye-lemon.github.io/post/be6/</id>
    <published>2021-12-16T15:11:03.000Z</published>
    <updated>2022-01-25T03:35:05.297Z</updated>
    
    <content type="html"><![CDATA[<ul><li>当我们落魄到需要去借别人的算力跑实验的时候，如何寄人篱下却依然衣冠楚楚。</li></ul><h2 id="使用-Docker-打包深度学习环境"><a href="#使用-Docker-打包深度学习环境" class="headerlink" title="使用 Docker 打包深度学习环境"></a>使用 Docker 打包深度学习环境</h2><ul><li><p>当我们落魄到需要去借别人的算力跑实验的时候，我们一定要尽可能高效率的完成自己的实验来少给别人添麻烦，那么配置环境就是一个相当耗时的工作，而且如果你有需要 root 权限，事情也会变得非常尴尬。这个时候，<code>Docker</code> 就可以帮我们做好环境的迁移工作。<del>毕竟，Docker 已经愈发变成一种基础设施了，尤其是对于那些卡特别多的团队，不像我们这种小实验室，人均 root 权限</del>。</p></li><li><p>而 nvidia-docker 为 Docker 提供了很好的显卡支持，非常适合我们来打包一个炼丹炉镜像。因此，我们需要在本地打包一个开箱即用的炼丹炉镜像，然后就可以拷贝到对方服务器上直接进入工作状态。<del>那么，为了让师弟师妹能够更加方便的“提镜像跑路”，我先把实验室的基础设施建好，从 Docker 的安装干起。</del></p><blockquote><p>今天你不努力，明天就有人替你努力。 </p><div style="text-align: right"> <i>—— 佚名</i> </div></blockquote></li></ul><h3 id="NVIDIA-Docker-的安装部署"><a href="#NVIDIA-Docker-的安装部署" class="headerlink" title="NVIDIA-Docker 的安装部署"></a>NVIDIA-Docker 的安装部署</h3><ul><li><p>NVIDIA-Docker 首先依赖 Docker 本身，故而第一步需要安装 Docker，其步骤如下：</p><ol><li><p>安装必要依赖；</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt install ca-certificates curl gnupg lsb-release</span><br></pre></td></tr></table></figure></li><li><p>添加 Docker 官方 GPG 公钥；</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg</span><br></pre></td></tr></table></figure></li><li><p>添加 Docker 镜像源；</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;deb [arch=<span class="subst">$(dpkg --print-architecture)</span> signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu <span class="subst">$(lsb_release -cs)</span> stable&quot;</span> | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null</span><br></pre></td></tr></table></figure></li><li><p>安装 Docker-CE；</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt install docker-ce docker-ce-cli containerd.io</span><br></pre></td></tr></table></figure></li><li><p>(Optional) 验证 Docker 安装情况。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker run hello-world</span><br></pre></td></tr></table></figure></li></ol></li><li><p>在完成了 Docker 的安装之后，即可安装 nvidia-docker，其步骤如下：</p><ol><li><p>配置 nvidia-docker 的存储库和 GPG 公钥；</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">distribution=$(. /etc/os-release;<span class="built_in">echo</span> $ID<span class="variable">$VERSION_ID</span>) &amp;&amp; curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add - &amp;&amp; curl -s -L https://nvidia.github.io/nvidia-docker/<span class="variable">$distribution</span>/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list</span><br></pre></td></tr></table></figure></li><li><p>(Optional) 添加 Experimental 功能支持；</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -s -L https://nvidia.github.io/nvidia-container-runtime/experimental/<span class="variable">$distribution</span>/nvidia-container-runtime.list | sudo tee /etc/apt/sources.list.d/nvidia-container-runtime.list</span><br></pre></td></tr></table></figure></li><li><p>安装 nvidia-docker；</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt install -y nvidia-docker2</span><br></pre></td></tr></table></figure></li><li><p>重新启动 Docker 守护进程以完成安装。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl restart docker</span><br></pre></td></tr></table></figure></li></ol></li></ul><h3 id="Docker-本地工作环境的补充工作"><a href="#Docker-本地工作环境的补充工作" class="headerlink" title="Docker 本地工作环境的补充工作"></a>Docker 本地工作环境的补充工作</h3><ul><li><p>既然都安装了 Docker 环境，那么我们这个小团队就也可以使用 Docker 来工作了，<del>毕竟，给一个未来的萌新师弟师妹 root 权限可能带来的影响实在是令人难以接受，君不见劳总连续 rm -rf / 了两次</del>。一种安全的方式就是给 Docker 用户组权限，这样可以让每一个用户以自己想要的方式在容器里折腾。</p></li><li><p>Docker 命令通过<code>UNIX Socket</code>建立通讯，默认情况下其只支持<code>root</code>用户或<code>docker</code>用户组中的用户访问。因此我们需要先创建 docker 用户组，可以使用<code>sudo groupadd docker</code>来完成，随后，可以通过<code>sudo usermod -aG docker [username]</code>的命令将某一用户加入 docker 用户组。如果上述修改未生效，可以重启 Docker 服务，重新登陆用户，使配置修改生效。</p></li><li><p>在实际工作中可以使用 Docker 命令启动容器，并指定端口映射以及文件挂载等操作，但我个人更喜欢通过<code>docker-compose</code>来启动，<del>毕竟，不会有人每次都重头敲一遍吧，反复按上键找命令也很不方便吧</del>。</p></li><li><p>Docker-Compose 的安装较为简单，有两个步骤：</p><ol><li><p>下载 docker-compose 的 release 文件（以最新版为例）；</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo curl -L <span class="string">&quot;https://github.com/docker/compose/releases/download/1.29.2/docker-compose-<span class="subst">$(uname -s)</span>-<span class="subst">$(uname -m)</span>&quot;</span> -o /usr/<span class="built_in">local</span>/bin/docker-compose</span><br></pre></td></tr></table></figure></li><li><p>授予其可执行权限。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo chmod +x /usr/<span class="built_in">local</span>/bin/docker-compose</span><br></pre></td></tr></table></figure></li></ol></li><li><p>为了让<code>docker-compose</code>命令自动调用<code>nvidia-docker</code>来执行命令，修改<code>/etc/docker/daemon.json</code>文件如下，此时，Docker 命令的执行就会由<code>nvidia-docker</code>来完成。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;default-runtime&quot;</span>: <span class="string">&quot;nvidia&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;runtimes&quot;</span>: &#123;</span><br><span class="line">        <span class="attr">&quot;nvidia&quot;</span>: &#123;</span><br><span class="line">            <span class="attr">&quot;path&quot;</span>: <span class="string">&quot;nvidia-container-runtime&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;runtimeArgs&quot;</span>: []</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h3 id="创建一个基于-Anaconda-的-Docker-镜像"><a href="#创建一个基于-Anaconda-的-Docker-镜像" class="headerlink" title="创建一个基于 Anaconda 的 Docker 镜像"></a>创建一个基于 Anaconda 的 Docker 镜像</h3><ul><li><p>为了更便捷的做一个开箱即用的炼丹炉镜像，我们可以充分利用一些现成的 Docker 镜像。比如，Anaconda 有自己官方的 Docker 镜像，我们可以以其作为基镜像快速构建一个面向我们自己具体 Task 的镜像文件。</p></li><li><p>Anaconda 在 <a href="https://hub.docker.com/u/continuumio">continuumio’s Profile | Docker Hub</a> 上提供了其官方 Docker 镜像，可以使用其 miniconda3 镜像作为基镜像创建一个自己的镜像文件，通过<code>conda env export &gt; env.yml</code>可以将本地的工作环境的全部依赖加以记录，将该配置文件<code>COPY</code>到<code>Dockerfile</code>中，从而在创建包含我们所需依赖的一个炼丹炉镜像。</p></li><li><p>一个典型的<code>Dockerfile</code>如下所示，包含了基础的 miniconda 环境、GPU支持的 PyTorch 框架以及 env.yml 中所要求的其他依赖。其中，<code>libgl1-mesa-glx</code>是解决 miniconda3 基镜像中，找不到<code>libGL.so.1</code>文件的问题。</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> continuumio/miniconda3</span><br><span class="line"></span><br><span class="line"><span class="keyword">LABEL</span><span class="bash"> author=<span class="string">&quot;Li Yingping&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apt update -q &amp;&amp; \</span></span><br><span class="line"><span class="bash">    apt install -q -y libgl1-mesa-glx</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> env.yml /build/env.yml</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> conda install pip</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> pip install torch==1.10.0+cu113 torchvision==0.11.1+cu113 torchaudio==0.10.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> conda env update -f /build/env.yml</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [ <span class="string">&quot;/bin/bash&quot;</span> ]</span></span><br></pre></td></tr></table></figure></li><li><p>完成 Dockerfile 的编写后，即可使用<code>docker build -t [image_name]:[tag_name] .</code>命令从当前文件夹构建一个镜像。</p></li><li><p>构建的过程需要大量下载文件，耗时且需要消耗大量流量，<del>至少，PyTorch 下载就需要 2G 多</del>，为了不给对方带来不必要的流量负担，<del>而且，万一对方为了避免挖矿切断了公网连接呢</del>，可以将本地构建好的镜像导出成文件，拷贝到对方的服务器中加载。</p><ul><li>Docker 导出镜像的命令：<code>docker save [image_name]:[tag_name] -o [filename].tar</code>；</li><li>Docker 载入镜像的命令：<code>docker load -i [image_name]:[tag_name]</code>。</li></ul></li></ul><h3 id="创建一个启动工程的-Docker-Compose-配置"><a href="#创建一个启动工程的-Docker-Compose-配置" class="headerlink" title="创建一个启动工程的 Docker-Compose 配置"></a>创建一个启动工程的 Docker-Compose 配置</h3><ul><li><p>一个典型的<code>docker-compose.yml</code>如下所示，其中</p><ul><li><code>image</code>字段指定使用哪个镜像运行程序；</li><li><code>volumes</code>字段指定需要将本地的哪些文件挂载到容器中，一般我们要挂载的包括代码文件夹、数据集和日志文件夹等；</li><li><code>ports</code>字段定义端口映射关系，一般我们要考虑映射<code>Jupyter Notebook</code>或<code>Tensor Board</code>等应用的端口；</li><li><code>environment</code>字段定义虚拟机中的环境变量，<code>NVIDIA_VISIBLE_DEVICES</code>定义物理机中哪些 GPU 设备对虚拟机可见，<code>CUDA_VISIBLE_DEVICES</code>定义虚拟机中哪些 GPU 设备对 PyTorch 可见；</li><li><code>shm_size</code>字段定义共享给虚拟机的内存空间；</li><li><code>working_dir</code>定义默认的工作目录，一般是容器中的代码目录；</li><li><code>command</code>定义启动命令，一般是执行某一<code>shell</code>脚本或运行某一<code>.py</code>文件等。</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">&quot;3.8&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">train:</span></span><br><span class="line">    <span class="attr">stdin_open:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">tty:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">build:</span> <span class="string">.</span></span><br><span class="line">    <span class="attr">image:</span> [<span class="string">image_name</span>]<span class="string">:[tag_name]</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/path/on/physical/machine:/path/on/virtual/machine</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> [<span class="string">local_port</span>]<span class="string">:[container_port]</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="attr">NVIDIA_VISIBLE_DEVICES:</span> <span class="string">all</span></span><br><span class="line">      <span class="attr">CUDA_VISIBLE_DEVICES:</span> [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="string">...</span>]</span><br><span class="line">    <span class="attr">shm_size:</span> <span class="string">32G</span></span><br><span class="line">    <span class="attr">working_dir:</span> <span class="string">/path/on/virtual/machine</span></span><br><span class="line">    <span class="attr">command:</span> <span class="string">&quot;/bin/bash run.sh&quot;</span></span><br></pre></td></tr></table></figure></li><li><p>当完成了 Docker-Compose 配置文件的编写之后，我们就可以使用<code>docker-compose up</code>的方式启动服务，需要关闭服务时使用<code>docker-compose down</code>，当文件夹下存在多个配置文件时<code>-f</code>选项可以用于指定将使用的配置文件，<code>-d</code>选项可以将所启动服务指定在后台静默运行。</p></li><li><p>当我们需要进入容器内进行 debug 时，可以使用<code>docker ps</code>命令获取当前运行中的容器的<code>CONTAINER ID</code>然后使用<code>docker exec -it [CONTAINER ID] /bin/bash</code>进入容器内 shell 开展调试。</p></li><li><p>By the way，我们也可以把容器的启动命令简单的设成 bash 本身，这样我们可以启动一个拥有完整环境的炼丹炉，不使用 volume 映射的方式挂载文件，这样挂载的文件夹与物理机是同步的，而使用<code>docker cp</code>命令独立的将文件拷贝进容器，这样可以避免本地修改了代码而影响一个正在运行的训练过程。</p></li></ul><h2 id="使用-rsync-传输数据集"><a href="#使用-rsync-传输数据集" class="headerlink" title="使用 rsync 传输数据集"></a>使用 rsync 传输数据集</h2><ul><li><p>当我们落魄到需要去借别人的算力跑实验的时候，Docker 可以帮我们实现运行环境的友好迁移，但数据集的迁移也是一个很大的问题。</p><ul><li>对于小规模的数据集可以在<code>Dockerfile</code>中用<code>COPY</code>命令将数据集复制到镜像内，制作一个更加开箱即用的炼丹炉镜像。</li><li>但是对于大规模数据集，这样会导致导出的镜像文件体积过大，显得笨重，因此，我们考虑使用网络传输大规模数据集，<del>毕竟，局域网又不消耗流量，也不会让资金窘迫的我们我们变得更加落魄</del>。</li></ul></li><li><p><code>rsync</code>是一款基于<code>scp</code>的文件同步工具，支持增量备份，可以配合其他工具实现多种触发类型的计划任务。这里，我们把它退化成一个普通的文件传输工具，用于将本地的数据集推送到远端。<code>rsync</code>的安装可以通过包管理工具朴素地安装，即<code>sudo apt install rsync</code>。</p></li><li><p><code>rsync</code>的基本语法如下，其支持三种工作模式，<strong>本地文件同步</strong>、<strong>通过 Remote Shell 的远程文件同步</strong>和<strong>通过 Rsync Deamon 的远程文件同步</strong>，三种命令均符合<code>rsync [OPTION...] SRC... [DEST]</code>的基本结构。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Local:</span>  </span><br><span class="line">rsync [OPTION...] SRC... [DEST]</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash"> Access via remote shell:</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Pull:</span></span> </span><br><span class="line">rsync [OPTION...] [USER@]HOST:SRC... [DEST]</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Push:</span></span> </span><br><span class="line">rsync [OPTION...] SRC... [USER@]HOST:DEST</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash"> Access via rsync daemon:</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Pull:</span></span> </span><br><span class="line">rsync [OPTION...] [USER@]HOST::SRC... [DEST]</span><br><span class="line">rsync [OPTION...] rsync://[USER@]HOST[:PORT]/SRC... [DEST]</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Push:</span></span> </span><br><span class="line">rsync [OPTION...] SRC... [USER@]HOST::DEST</span><br><span class="line">rsync [OPTION...] SRC... rsync://[USER@]HOST[:PORT]/DEST</span><br></pre></td></tr></table></figure></li><li><p>就我们的任务而言，我们需要的是其中的第二种方式，可以使用下列命令完成数据集的传输，过程中需要输入相应服务器的密码以建立连接。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 如果在本地将数据推送到远程服务器</span></span><br><span class="line">rsync -r /path/to/local/dataset [remote_username]@[remote_ip]:/path/to/remote/dataset</span><br><span class="line"><span class="meta">#</span><span class="bash"> 如果使用SSH连接了远程服务器希望拉取本地的数据</span></span><br><span class="line">rsync -r [local_username]@[local_ip]:/path/to/local/dataset /path/to/remote/dataset</span><br></pre></td></tr></table></figure></li><li><p>需要注意的是，源路径末尾带斜线，传输的是目录中所有的文件而不包括目录本身，而不带斜线的话，会在目的路径创建一个同名目录以及所有文件。具体的，上面的示例会在远程服务器中呈现<code>/path/to/remote/dataset/dataset/***(files)</code>。</p></li><li><p><code>rsync</code>的其他用法可以参考下列链接，或者简单地通过<code>rsync -h</code>或<code>tldr rsync</code>了解。</p><blockquote><p><strong>rsync 官方网站：</strong><a href="https://rsync.samba.org/">rsync (samba.org)</a></p><p><strong>阮一峰 rsync 教程：</strong><a href="https://www.ruanyifeng.com/blog/2020/08/rsync.html">rsync 用法教程 - 阮一峰的网络日志 (ruanyifeng.com)</a></p></blockquote></li></ul><h2 id="使用脚本批量运行程序"><a href="#使用脚本批量运行程序" class="headerlink" title="使用脚本批量运行程序"></a>使用脚本批量运行程序</h2><ul><li><p>当我们落魄到需要去借别人的算力跑实验的时候，我们一定要尽可能高效率的完成自己的实验来少给别人添麻烦。众所周知，<del>炼丹就是黑心资本家对于显卡这一劳动力的无情剥削</del>，因此，充分利用显卡的空余时间能帮助我们尽早完成炼丹任务。与其熬夜等结果，不如写个脚本自动值守。</p></li><li><p>一个朴素的想法是，构建训练任务队列，轮询显卡的使用情况，监测到有空闲显卡，则从队列中选择一个工程启动。</p><blockquote><p>人与猴子最大的区别在于创造并使用工具。</p><div style="text-align: right"> <i>—— 佚名（忘了谁说的，只能请出佚名兄了，要不，鲁迅？）</i> </div></blockquote></li></ul><h3 id="使用-shutil-批量创建实验工程"><a href="#使用-shutil-批量创建实验工程" class="headerlink" title="使用 shutil 批量创建实验工程"></a>使用 shutil 批量创建实验工程</h3><ul><li>在消融实验中，难免存在大量基本代码类似，仅仅参数或设置不同的情况，为了高效的进行实验，可以率先将同样的工程模板复制若干份，每份对应一个实验，尔后，集中修改每一个实验中不同的部分，这个复制的过程可以使用标准库 <code>shutil</code> 中的 <code>copytree()</code> 函数来完成，对于不需要复制的部分，可以在参数中传入 glob 形式的匹配模板来指定。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shutil.copytree([base_exper_dir], [target_exper_dir], ignore=shutil.ignore_patterns(<span class="string">&#x27;apex&#x27;</span>, <span class="string">&#x27;vis&#x27;</span>))</span><br></pre></td></tr></table></figure></li></ul><h3 id="使用-pynvml-监控显卡使用情况"><a href="#使用-pynvml-监控显卡使用情况" class="headerlink" title="使用 pynvml 监控显卡使用情况"></a>使用 pynvml 监控显卡使用情况</h3><ul><li><p><strong>pynvml</strong> 是英伟达显卡管理库 <strong>NVML</strong> 的一个 Python 绑定，可以通过该模块获取到类似<code>nvidia-smi</code>命令的查询结果，使用<code>pip install nvidia-ml-py</code>命令可以完成模块的安装。在我们的任务需求中，我们需要监控显卡使用情况，因此，需要获取主机上的显卡数目，并查询每一张显卡上的显存占用，从而判断是否可以支持工程的运行。其他功能接口可以参考下述仓库：</p><blockquote><p><strong>pynvml 官方 Repo：</strong><a href="https://github.com/gpuopenanalytics/pynvml">https://github.com/gpuopenanalytics/pynvml</a></p><p><strong>NVML API 文档：</strong><a href="https://docs.nvidia.com/deploy/nvml-api/">https://docs.nvidia.com/deploy/nvml-api/</a></p></blockquote></li><li><p><strong>pynvml</strong> 使用前后需要先后调用<code>nvmlInit()</code>和<code>nvmlShutdown()</code>两个函数来管理上下文，<code>nvmlDeviceGetCount()</code>函数返回设备上总的 GPU 的数目，随后可以通过循环的方式查询每一张显卡的使用情况。给定 gpu_id 可以通过<code>nvmlDeviceGetHandleByIndex()</code>返回一个对应该设备的句柄，<code>nvmlDeviceGetMemoryInfo()</code>接受一个句柄作为输入，返回其显存使用情况，其返回值的<code>used</code>属性即是已使用的显存，为方便计算，将结果右移 20 位，将单位转换为 MB。此时，即可通过一个预设的阈值判断是否有程序在占用显存，从而判定其是否在使用。核心代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">query_devices_mems</span>():</span></span><br><span class="line">    pynvml.nvmlInit()</span><br><span class="line">    devices = pynvml.nvmlDeviceGetCount()</span><br><span class="line">    used_mems = []</span><br><span class="line">    <span class="keyword">for</span> id_ <span class="keyword">in</span> <span class="built_in">range</span>(devices):</span><br><span class="line">        device = pynvml.nvmlDeviceGetHandleByIndex(id_)</span><br><span class="line">        mem_info = pynvml.nvmlDeviceGetMemoryInfo(device)</span><br><span class="line">        mem_used = mem_info.used &gt;&gt; <span class="number">20</span></span><br><span class="line">        used_mems.append(mem_used)</span><br><span class="line">    pynvml.nvmlShutdown()</span><br><span class="line">    <span class="keyword">return</span> used_mems</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">query_free_gpus</span>(<span class="params">threshold=<span class="number">2000</span></span>):</span></span><br><span class="line">    used_mems = query_devices_mems()</span><br><span class="line">    free_gpus = [idx <span class="keyword">for</span> idx, mem <span class="keyword">in</span> <span class="built_in">enumerate</span>(used_mems) <span class="keyword">if</span> mem &lt; threshold]</span><br><span class="line">    <span class="keyword">return</span> free_gpus</span><br></pre></td></tr></table></figure></li></ul><h3 id="使用-subprocess-启动实验工程"><a href="#使用-subprocess-启动实验工程" class="headerlink" title="使用 subprocess 启动实验工程"></a>使用 subprocess 启动实验工程</h3><ul><li>当监测到空闲 GPU 之后，即可取出队列中的下一个工程并运行，一种简单的方式是通过标准库中的 <strong>subprocess</strong> 模块来启动。其优势在于，<code>subprocess.run()</code>接口提供了丰富的自定义参数，<code>env</code>参数允许可以传入子进程运行的环境变量，我们可以通过复制当前环境变量并修改<code>CUDA_VISIBLE_DEVICES</code>的值来为工程指定到空闲的 GPU 上。同时，<code>cwd</code>字段允许指定工作目录，可以在此处传入对应工程路径以保证程序中的相对路径可以正确解析到需要的位置。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_script</span>(<span class="params">script_path, gpu_id</span>):</span></span><br><span class="line">    command = <span class="string">f&quot;/bin/bash <span class="subst">&#123;script_path&#125;</span>&quot;</span></span><br><span class="line">    subenv = os.environ.copy()</span><br><span class="line">    subenv[<span class="string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>] = <span class="built_in">str</span>(gpu_id)</span><br><span class="line">    ret = subprocess.run(</span><br><span class="line">        command, shell=<span class="literal">True</span>,</span><br><span class="line">        stdout=subprocess.PIPE, stderr=subprocess.PIPE,</span><br><span class="line">        encoding=<span class="string">&quot;utf-8&quot;</span>, env=subenv,</span><br><span class="line">        cwd=op.dirname(script_path))</span><br><span class="line">    <span class="keyword">if</span> ret.returncode == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">f&quot;[SUBPROCESS]  Experiment <span class="subst">&#123;script_path.split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>]&#125;</span> run successfully ...&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(<span class="string">f&quot;[SUBPROCESS]  Experiment <span class="subst">&#123;script_path.split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>]&#125;</span> failed with <span class="subst">&#123;ret&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure></li></ul><h3 id="一个简单的调度例程"><a href="#一个简单的调度例程" class="headerlink" title="一个简单的调度例程"></a>一个简单的调度例程</h3><ul><li>通过第三方库<code>fire</code>可以为程序创建命令行接口，下面的例程可以通过<code>python xxxx.py create_experiments</code>来创建工程，修改好每一个工程之后可以通过<code>python xxxx.py dispatch</code>来启动调度。种子撒出去了之后等几天再来收菜就好了。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> fire</span><br><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> os.path <span class="keyword">as</span> op</span><br><span class="line"><span class="keyword">import</span> pynvml</span><br><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"><span class="keyword">import</span> subprocess</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line">exper_names = [</span><br><span class="line">    <span class="string">&quot;Exper1&quot;</span>, <span class="string">&quot;Exper2&quot;</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">path = <span class="string">&quot;[PATH]&quot;</span></span><br><span class="line">base_exper_dir = <span class="string">&quot;[SOURCE_PATH]&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_experiments</span>():</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> op.exists(path):</span><br><span class="line">        os.mkdir(path)</span><br><span class="line">    <span class="keyword">for</span> name <span class="keyword">in</span> tqdm.tqdm(exper_names):</span><br><span class="line">        abs_path = op.join(path, name)</span><br><span class="line">        shutil.copytree(base_exper_dir, abs_path,</span><br><span class="line">         ignore=shutil.ignore_patterns(<span class="string">&#x27;apex&#x27;</span>, <span class="string">&#x27;vis&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_experiments</span>():</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> op.exists(path):</span><br><span class="line">        os.mkdir(path)</span><br><span class="line">    <span class="keyword">for</span> name <span class="keyword">in</span> tqdm.tqdm(exper_names):</span><br><span class="line">        abs_path = op.join(path, name)</span><br><span class="line">        shutil.copytree(base_exper_dir, abs_path,</span><br><span class="line">         ignore=shutil.ignore_patterns(<span class="string">&#x27;apex&#x27;</span>, <span class="string">&#x27;vis&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">query_devices_mems</span>():</span></span><br><span class="line">    pynvml.nvmlInit()</span><br><span class="line">    devices = pynvml.nvmlDeviceGetCount()</span><br><span class="line">    used_mems = []</span><br><span class="line">    <span class="keyword">for</span> id_ <span class="keyword">in</span> <span class="built_in">range</span>(devices):</span><br><span class="line">        device = pynvml.nvmlDeviceGetHandleByIndex(id_)</span><br><span class="line">        mem_info = pynvml.nvmlDeviceGetMemoryInfo(device)</span><br><span class="line">        mem_used = mem_info.used &gt;&gt; <span class="number">20</span></span><br><span class="line">        used_mems.append(mem_used)</span><br><span class="line">    pynvml.nvmlShutdown()</span><br><span class="line">    <span class="keyword">return</span> used_mems</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">query_free_gpus</span>(<span class="params">threshold = <span class="number">2000</span></span>):</span></span><br><span class="line">    used_mems = query_devices_mems()</span><br><span class="line">    free_gpus = [idx <span class="keyword">for</span> idx, mem <span class="keyword">in</span> <span class="built_in">enumerate</span>(used_mems) <span class="keyword">if</span> mem &lt; threshold]</span><br><span class="line">    <span class="keyword">return</span> free_gpus</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_script</span>(<span class="params">script_path, gpu_id</span>):</span></span><br><span class="line">    command = <span class="string">f&quot;/bin/bash <span class="subst">&#123;script_path&#125;</span>&quot;</span></span><br><span class="line">    subenv = os.environ.copy()</span><br><span class="line">    subenv[<span class="string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>] = <span class="built_in">str</span>(gpu_id)</span><br><span class="line">    ret = subprocess.run(</span><br><span class="line">        command, shell=<span class="literal">True</span>,</span><br><span class="line">        stdout=subprocess.PIPE, stderr=subprocess.PIPE,</span><br><span class="line">        encoding=<span class="string">&quot;utf-8&quot;</span>, env=subenv,</span><br><span class="line">        cwd=op.dirname(script_path))</span><br><span class="line">    <span class="keyword">if</span> ret.returncode == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">f&quot;[SUBPROCESS]  Experiment <span class="subst">&#123;script_path.split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>]&#125;</span> run successfully ...&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(<span class="string">f&quot;[SUBPROCESS]  Experiment <span class="subst">&#123;script_path.split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>]&#125;</span> failed with <span class="subst">&#123;ret&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">wait_until_run</span>(<span class="params">project, interval=<span class="number">2</span></span>):</span></span><br><span class="line">    free_gpus = query_free_gpus()</span><br><span class="line">    iter_ = itertools.cycle([<span class="string">&quot;\\&quot;</span>, <span class="string">&quot;|&quot;</span>, <span class="string">&quot;/&quot;</span>, <span class="string">&quot;-&quot;</span>])</span><br><span class="line">    <span class="keyword">while</span> <span class="built_in">len</span>(free_gpus) == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">f&quot;\r[DISPATCHER]  Waiting for free GPU <span class="subst">&#123;<span class="built_in">next</span>(iter_)&#125;</span>&quot;</span>, end=<span class="string">&quot;&quot;</span>)</span><br><span class="line">        time.sleep(interval)</span><br><span class="line">        free_gpus = query_free_gpus()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(<span class="string">f&quot;\r[DISPATCHER]  Waiting for free GPU <span class="subst">&#123;<span class="built_in">next</span>(iter_)&#125;</span>&quot;</span>)</span><br><span class="line">    free_gpu = free_gpus[<span class="number">0</span>]</span><br><span class="line">    print(<span class="string">f&quot;[DISPATCHER]  GPU-<span class="subst">&#123;free_gpu&#125;</span> is free ...&quot;</span>)</span><br><span class="line">    script_path = op.join(project, <span class="string">&quot;run.sh&quot;</span>)</span><br><span class="line">    print(<span class="string">f&quot;[DISPATCHER]  Start running <span class="subst">&#123;project&#125;</span> ...&quot;</span>)</span><br><span class="line">    t = threading.Thread(target=run_script, kwargs=&#123;<span class="string">&quot;script_path&quot;</span>: script_path, <span class="string">&quot;gpu_id&quot;</span>: free_gpu&#125;)</span><br><span class="line">    t.start()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dispatch</span>():</span>   </span><br><span class="line">    <span class="keyword">for</span> exper_name <span class="keyword">in</span> exper_names:</span><br><span class="line">        project_path = op.join(path, exper_name)</span><br><span class="line">        print(<span class="string">f&quot;[DISPATCHER]  <span class="subst">&#123;exper_name&#125;</span> is waiting ...&quot;</span>)</span><br><span class="line">        wait_until_run(project_path)</span><br><span class="line">        time.sleep(<span class="number">30</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    fire.Fire()</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;当我们落魄到需要去借别人的算力跑实验的时候，如何寄人篱下却依然衣冠楚楚。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;使用-Docker-打包深度学习环境&quot;&gt;&lt;a href=&quot;#使用-Docker-打包深度学习环境&quot; class=&quot;headerlink&quot; title=</summary>
      
    
    
    
    <category term="开发和调试笔记" scheme="http://bye-lemon.github.io/categories/%E5%BC%80%E5%8F%91%E5%92%8C%E8%B0%83%E8%AF%95%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="docker" scheme="http://bye-lemon.github.io/tags/docker/"/>
    
    <category term="nvidia-docker" scheme="http://bye-lemon.github.io/tags/nvidia-docker/"/>
    
    <category term="docker-compose" scheme="http://bye-lemon.github.io/tags/docker-compose/"/>
    
    <category term="rsync" scheme="http://bye-lemon.github.io/tags/rsync/"/>
    
  </entry>
  
  <entry>
    <title>借助SSH反向代理隧道实现内网服务器的校外访问</title>
    <link href="http://bye-lemon.github.io/post/6c49/"/>
    <id>http://bye-lemon.github.io/post/6c49/</id>
    <published>2021-08-12T13:57:15.000Z</published>
    <updated>2021-08-12T14:23:46.259Z</updated>
    
    <content type="html"><![CDATA[<ol><li><p>首先要建立内网目标机与公网跳板机之间的SSH连接，在内网目标机中使用下述命令生成一组密钥对。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa</span><br></pre></td></tr></table></figure></li><li><p>使用下述命令将生成的密钥添加到公网跳板机的<code>authorized_keys</code>中，如此，即可建立两者之间的SSH连接。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-copy-id [Board Machine Username]@[Board Machine IP Address]</span><br></pre></td></tr></table></figure></li><li><p>修改跳板机的配置文件<code>/etc/ssh/sshd_config</code>，将其中<code>#GatewayPorts no</code>一行的注释取消，并将其配置值修改为<code>yes</code>。</p></li><li><p>使用下述命令重启跳板机的<code>sshd</code>服务，使配置修改生效。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo service sshd restart</span><br></pre></td></tr></table></figure></li><li><p>在目标机中使用命令<code>sudo apt install autossh</code>安装<code>AutoSSH</code>，并执行以下命令创建反向代理。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">autossh -M [Any Available Port] -NfR 0.0.0.0:[Board Machine Binding Port]:localhost:22 [Board Machine Username]@[Board Machine IP Address]</span><br></pre></td></tr></table></figure></li><li><p>若目标机有安全组策略，需要在入站规则中放行上述命令中使用的端口。</p></li><li><p>至此，SSH隧道建立完毕，此时在跳板机所绑定端口上的访问均会被转发至目标机22端口，由此，便可以借助跳板机连接内网服务器，执行作业。使用方式为：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh [Target Machine Username]@[Board Machine IP Address] -p [Board Machine Binding Port]</span><br></pre></td></tr></table></figure></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;ol&gt;
&lt;li&gt;&lt;p&gt;首先要建立内网目标机与公网跳板机之间的SSH连接，在内网目标机中使用下述命令生成一组密钥对。&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class</summary>
      
    
    
    
    <category term="开发和调试笔记" scheme="http://bye-lemon.github.io/categories/%E5%BC%80%E5%8F%91%E5%92%8C%E8%B0%83%E8%AF%95%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="DLUT" scheme="http://bye-lemon.github.io/tags/DLUT/"/>
    
  </entry>
  
  <entry>
    <title>Windows 10系统下使用SMB实现媒体文件共享</title>
    <link href="http://bye-lemon.github.io/post/f81/"/>
    <id>http://bye-lemon.github.io/post/f81/</id>
    <published>2021-02-25T11:03:25.000Z</published>
    <updated>2021-02-25T11:05:56.664Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Step-1、打开SMB服务"><a href="#Step-1、打开SMB服务" class="headerlink" title="Step 1、打开SMB服务"></a>Step 1、打开SMB服务</h2><hr><ul><li><p>由于存在一定的安全漏洞，Windows 10系统默认禁用了SMB服务。因此，需要手动打开SMB服务，具体的操作流程如下：</p><ol><li><p>使用<code>Win+R</code>快捷键打开运行，输入<code>control</code>并回车打开控制面板。</p><p><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20210225174951.png" alt="image-20210225174947991"></p></li><li><p>点击<code>程序</code>，进入程序选项卡组。</p><p><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20210225175103.png" alt="image-20210225175103685"></p></li><li><p>在<code>程序与功能</code>中点击<code>启用或关闭Windows功能</code>。</p><p><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20210225175320.png" alt="image-20210225175320239"></p></li><li><p>在弹出的对话框中勾选上<code>SMB 1.0/CIFS 文件共享支持</code>，之后点击<code>确定</code>。</p><p><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20210225175359.png" alt="image-20210225175359504"></p></li><li><p>等待系统下载所需要的组建之后，重启计算机，应用更改，启用相应的功能。</p></li></ol></li></ul><h2 id="Step-2、开启局域网内文件共享服务"><a href="#Step-2、开启局域网内文件共享服务" class="headerlink" title="Step 2、开启局域网内文件共享服务"></a>Step 2、开启局域网内文件共享服务</h2><hr><ul><li><p>开启SMB服务之后，需要开启局域网内的共享，具体流程如下：</p><ol><li><p>在通知栏中右击网络图标，点击<code>打开“网络和Internet”设置</code>。</p><p><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20210225180141.png" alt="image-20210225180141304"></p></li><li><p>在弹出的页面中点击<code>网络与共享中心</code>。</p><p><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20210225180327.png" alt="image-20210225180327602"></p></li><li><p>在弹出的页面中点击左侧选项卡中的<code>更改高级共享设置</code>。</p><p><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20210225180431.png" alt="image-20210225180431490"></p></li><li><p>启用<code>网络发现</code>，设置<code>有密码访问的共享</code>。</p><p><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20210225180607.png" alt="image-20210225180607240"></p><p><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20210225180656.png" alt="image-20210225180656545"></p></li></ol></li></ul><h2 id="Step-3、设置共享文件夹"><a href="#Step-3、设置共享文件夹" class="headerlink" title="Step 3、设置共享文件夹"></a>Step 3、设置共享文件夹</h2><hr><ul><li><p>完成前两步操作之后，即可为需要共享的文件夹设置共享，具体操作如下：</p><ol><li><p>在想共享的文件夹上右击，在右键菜单里点击<code>属性</code>。</p><p><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20210225181229.png" alt="image-20210225181229281"></p></li><li><p>在弹出的对话框中选择<code>共享</code>选项卡，在<code>网络文件和文件夹共享</code>中点击<code>共享</code>。</p><p><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20210225184222.png" alt="image-20210225184222073"></p></li><li><p>在弹出的对话框中选择当前用户，点击<code>添加</code>，随后点击<code>共享</code>，如果看到下方图二就说明已经共享成功。</p><p><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20210225184601.png" alt="image-20210225184601265"></p><p><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20210225190452.png" alt=""></p></li></ol></li></ul><h2 id="Step-4、访问共享文件夹"><a href="#Step-4、访问共享文件夹" class="headerlink" title="Step 4、访问共享文件夹"></a>Step 4、访问共享文件夹</h2><hr><ul><li>对于Android设备，可以使用带有SMB功能的播放器访问共享的文件夹，比如<strong>VLC</strong>，最新版本的VLC下载地址为<a href="https://get.videolan.org/vlc-android/3.3.0/VLC-Android-3.3.0-arm64-v8a.apk。">https://get.videolan.org/vlc-android/3.3.0/VLC-Android-3.3.0-arm64-v8a.apk。</a></li><li>对于iOS设备，可以在App Store上搜索下载<strong>VLC</strong>或<strong>APlayer</strong>等软件访问共享的媒体文件夹。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Step-1、打开SMB服务&quot;&gt;&lt;a href=&quot;#Step-1、打开SMB服务&quot; class=&quot;headerlink&quot; title=&quot;Step 1、打开SMB服务&quot;&gt;&lt;/a&gt;Step 1、打开SMB服务&lt;/h2&gt;&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;由于存在一定的安</summary>
      
    
    
    
    <category term="英平的工具箱" scheme="http://bye-lemon.github.io/categories/%E8%8B%B1%E5%B9%B3%E7%9A%84%E5%B7%A5%E5%85%B7%E7%AE%B1/"/>
    
    
    <category term="SMB" scheme="http://bye-lemon.github.io/tags/SMB/"/>
    
    <category term="Windows 10" scheme="http://bye-lemon.github.io/tags/Windows-10/"/>
    
  </entry>
  
  <entry>
    <title>避重就轻的论文阅读笔记</title>
    <link href="http://bye-lemon.github.io/post/fab7/"/>
    <id>http://bye-lemon.github.io/post/fab7/</id>
    <published>2021-01-29T06:58:56.000Z</published>
    <updated>2021-08-18T04:48:03.507Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Computer-Vision"><a href="#Computer-Vision" class="headerlink" title="Computer Vision"></a>Computer Vision</h2><hr><h3 id="Object-Detection"><a href="#Object-Detection" class="headerlink" title="Object Detection"></a>Object Detection</h3><ul><li><a href="/post/dbc2/" title="《YOLO v4: Optimal Speed and Accuracy of Object Detection》论文笔记">《YOLO v4: Optimal Speed and Accuracy of Object Detection》论文笔记</a></li></ul><h3 id="Person-Re-identification"><a href="#Person-Re-identification" class="headerlink" title="Person Re-identification"></a>Person Re-identification</h3><ul><li><a href="/post/cde6/" title="行人重识别（Person Re-identification）研究概述">行人重识别（Person Re-identification）研究概述</a></li><li><a href="/post/aa5f/" title="《COCAS: A Large-Scale Clothes Changing Person Dataset for Re-identification》论文笔记">《COCAS: A Large-Scale Clothes Changing Person Dataset for Re-identification》论文笔记</a></li><li><a href="/post/8337/" title="《Pose-guided Visible Part Matching for Occluded Person ReID》论文笔记">《Pose-guided Visible Part Matching for Occluded Person ReID》论文笔记</a></li><li><a href="/post/7f95/" title="《Transferable, Controllable, and Inconspicuous Adversarial Attacks on Person Re-identification With Deep Mis-Ranking》论文笔记">《Transferable, Controllable, and Inconspicuous Adversarial Attacks on Person Re-identification With Deep Mis-Ranking》论文笔记</a></li><li><a href="/post/4d08/" title="《Weakly supervised discriminative feature learning with state information for person identification》论文笔记">《Weakly supervised discriminative feature learning with state information for person identification》论文笔记</a></li></ul><h3 id="Person-Search"><a href="#Person-Search" class="headerlink" title="Person Search"></a>Person Search</h3><ul><li><a href="/post/c6f5/" title="《Joint Detection and Identification Feature Learning for Person Search》论文笔记">《Joint Detection and Identification Feature Learning for Person Search》论文笔记</a></li><li><a href="/post/ffa2/" title="《Query-guided End-to-End Person Search》论文笔记">《Query-guided End-to-End Person Search》论文笔记</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Computer-Vision&quot;&gt;&lt;a href=&quot;#Computer-Vision&quot; class=&quot;headerlink&quot; title=&quot;Computer Vision&quot;&gt;&lt;/a&gt;Computer Vision&lt;/h2&gt;&lt;hr&gt;
&lt;h3 id=&quot;Object-D</summary>
      
    
    
    
    <category term="英平的工具箱" scheme="http://bye-lemon.github.io/categories/%E8%8B%B1%E5%B9%B3%E7%9A%84%E5%B7%A5%E5%85%B7%E7%AE%B1/"/>
    
    
    <category term="导航" scheme="http://bye-lemon.github.io/tags/%E5%AF%BC%E8%88%AA/"/>
    
  </entry>
  
  <entry>
    <title>DLUT校园网自动认证的解决方案</title>
    <link href="http://bye-lemon.github.io/post/258b/"/>
    <id>http://bye-lemon.github.io/post/258b/</id>
    <published>2021-01-17T03:30:50.000Z</published>
    <updated>2021-01-17T06:03:10.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><hr><ul><li><p>耀波师兄曾经给过我一个文档，记录了早年间，他在树莓派的命令行下认证DLUT的解决方案，其思路基本是抓包再重放。运恒跟我提出想要一个脚本实现服务器开机自动认证校园网之后，我本想使用无头浏览器模拟点击的方式登录，想到师兄当年的这个经验之后，我觉得也是一个很方便的方案，简单暴力，于是复现了一遍师兄的思路。</p></li><li><p>在具体的实施过程中，可能需要Fiddler4来进行网络抓包，由于程序使用Java开发，所以需要JDK和IDEA这样的集成开发环境支持，相应软件的下载链接如下：</p><blockquote><p>Fiddler 4官网：<a href="https://www.telerik.com/download/fiddler">https://www.telerik.com/download/fiddler</a><br>OpenJDK 11官网：<a href="http://openjdk.java.net/projects/jdk/11/">http://openjdk.java.net/projects/jdk/11/</a><br>IntelliJ IDEA官网：<a href="https://www.jetbrains.com/idea/">https://www.jetbrains.com/idea/</a></p></blockquote></li></ul><h2 id="抓包"><a href="#抓包" class="headerlink" title="抓包"></a>抓包</h2><hr><ul><li><p>在<a href="http://auth.dlut.edu.cn">auth.dlut.edu.cn</a>上退出已经认证的账号，再重新登录，使用Fiddler4或Chrome Dev Tools捕获点击登录之后发出的POST请求，以RAW的方式查看，会得到一条形如下文所示的报文。需要注意的是，使用Chrome Dev Tools需要勾选<code>Preserve log</code>的复选框，否则Chrome Dev Tools会在页面发生更新时清除此前的记录，校园网认证页面登录后会跳转新页面，原页面的记录将会被清除，会导致找不到POST提交。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">POST http:&#x2F;&#x2F;auth.dlut.edu.cn&#x2F;eportal&#x2F;InterFace.do?method&#x3D;login HTTP&#x2F;1.1</span><br><span class="line">Host: auth.dlut.edu.cn</span><br><span class="line">Proxy-Connection: keep-alive</span><br><span class="line">Content-Length: 642</span><br><span class="line">User-Agent: Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;87.0.4280.141 Safari&#x2F;537.36 Edg&#x2F;87.0.664.75</span><br><span class="line">Content-Type: application&#x2F;x-www-form-urlencoded; charset&#x3D;UTF-8</span><br><span class="line">Accept: *&#x2F;*</span><br><span class="line">Origin: http:&#x2F;&#x2F;auth.dlut.edu.cn</span><br><span class="line">Referer: http:&#x2F;&#x2F;auth.dlut.edu.cn&#x2F;eportal&#x2F;index.jsp?wlanuserip&#x3D;***************************</span><br><span class="line">Accept-Encoding: gzip, deflate</span><br><span class="line">Accept-Language: zh-CN,zh;q&#x3D;0.9,en;q&#x3D;0.8,en-GB;q&#x3D;0.7,en-US;q&#x3D;0.6</span><br><span class="line">Cookie: EPORTAL_COOKIE_SAVEPASSWORD&#x3D;true; EPORTAL_AUTO_LAND&#x3D;; EPORTAL_COOKIE_OPERATORPWD&#x3D;; EPORTAL_COOKIE_USERNAME&#x3D;********************</span><br><span class="line"></span><br><span class="line">userId&#x3D;************************</span><br></pre></td></tr></table></figure></li><li><p>将上述报文内容保存到本地，编写程序进行重放即可完成校园网的认证。此处插一句吐槽，明文传输用户名密码真是我校保留节目了。</p></li></ul><h2 id="重放"><a href="#重放" class="headerlink" title="重放"></a>重放</h2><hr><ul><li><p>作为一个很“不讲武德”的方法，该方案最优的一点在于简单暴力，不像无头浏览器模拟点击需要分析网页或者模拟POST请求需要解析报文字段，该方案将捕获的报文当做一个完整的TCP数据报，通过Socket直接发送，简单有效。</p></li><li><p>为了实现Java的重放，我在耀波师兄的基础上维护了一个Java的程序，该程序延续PING百度的光荣传统，如果发现PING不通就使用所捕获的报文重新认证网络，代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.net.InetAddress;</span><br><span class="line"><span class="keyword">import</span> java.nio.ByteBuffer;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.SocketChannel;</span><br><span class="line"><span class="keyword">import</span> java.net.InetSocketAddress;</span><br><span class="line"><span class="keyword">import</span> java.nio.charset.StandardCharsets;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="keyword">static</span> String auth = <span class="string">&quot;POST http://auth.dlut.edu.cn/eportal/InterFace.do?method=login HTTP/1.1\n&quot;</span></span><br><span class="line">            + <span class="string">&quot;Host: auth.dlut.edu.cn\n&quot;</span> + <span class="string">&quot;Proxy-Connection: keep-alive\n&quot;</span> + <span class="string">&quot;Content-Length: 642\n&quot;</span></span><br><span class="line">            + <span class="string">&quot;User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36 Edg/87.0.664.75\n&quot;</span></span><br><span class="line">            + <span class="string">&quot;Content-Type: application/x-www-form-urlencoded; charset=UTF-8\n&quot;</span> + <span class="string">&quot;Accept: */*\n&quot;</span></span><br><span class="line">            + <span class="string">&quot;Origin: http://auth.dlut.edu.cn\n&quot;</span></span><br><span class="line">            + <span class="string">&quot;Referer: http://auth.dlut.edu.cn/eportal/index.jsp?wlanuserip=***********\n&quot;</span></span><br><span class="line">            + <span class="string">&quot;Accept-Encoding: gzip, deflate\n&quot;</span> + <span class="string">&quot;Accept-Language: zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6\n&quot;</span></span><br><span class="line">            + <span class="string">&quot;Cookie: EPORTAL_COOKIE_SAVEPASSWORD=true; EPORTAL_AUTO_LAND=; EPORTAL_COOKIE_OPERATORPWD=; EPORTAL_COOKIE_USERNAME=***********\n&quot;</span></span><br><span class="line">            + <span class="string">&quot;\n&quot;</span></span><br><span class="line">            + <span class="string">&quot;userId=***************&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">ping</span><span class="params">(String address)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> timeOut = <span class="number">3000</span>;</span><br><span class="line">        <span class="keyword">boolean</span> status = InetAddress.getByName(address).isReachable(timeOut);</span><br><span class="line">        <span class="keyword">return</span> status;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (ping(<span class="string">&quot;www.baidu.com&quot;</span>)) &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;Baidu reachable\n&quot;</span>);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;Baidu unreachable\n&quot;</span>);</span><br><span class="line">                System.out.println(<span class="string">&quot;Using LYP&#x27;s authentication\n&quot;</span>);</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    SocketChannel socketChannel = SocketChannel.open();</span><br><span class="line">                    socketChannel.connect(<span class="keyword">new</span> InetSocketAddress(<span class="string">&quot;auth.dlut.edu.cn&quot;</span>, <span class="number">80</span>));</span><br><span class="line">                    socketChannel.write(ByteBuffer.wrap(auth.getBytes()));</span><br><span class="line">                    ByteBuffer buffer = ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line">                    <span class="keyword">while</span> (socketChannel.read(buffer) &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                        buffer.flip();</span><br><span class="line">                        String content = StandardCharsets.UTF_8.decode(buffer).toString();</span><br><span class="line">                        System.out.println(content + <span class="string">&quot;\n&quot;</span>);</span><br><span class="line">                        buffer.clear();</span><br><span class="line">                    &#125;</span><br><span class="line">                    socketChannel.close();</span><br><span class="line">                &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                    <span class="keyword">if</span> (ping(<span class="string">&quot;www.baidu.com&quot;</span>)) &#123;</span><br><span class="line">                        System.out.println(<span class="string">&quot;Baidu reachable\n&quot;</span>);</span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                        System.out.println(<span class="string">&quot;Baidu unreachable\n&quot;</span>);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>将程序打包成<code>.jar</code>的包保存到本地，就构成了一个令牌，使用其即可使用自己的身份授权校园网的登录。</p></li></ul><h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><hr><ul><li><p>对于树莓派来说，其自带Java的运行环境，可以直接使用<code>java -jar token.jar</code>来运行程序完成认证，在命令行下，使用<code>sudo iwconfig wlan0 essid [Wi-Fi Name]</code>即可连接到网络下，使用前述命令即可完成认证。</p></li><li><p>对于一台普通的Ubuntu服务器，需要先安装JRE，可以使用<code>sudo apt install default-jre</code>完成JRE的安装，然后，同样可以使用<code>java -jar token.jar</code>来运行程序完成认证。</p></li><li><p>为了实现开机自动认证，可以将这一命令加入到<code>/etc/rc.local</code>下；为了实现每日定时运行，可以借助<code>crontab</code>命令。</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;准备&quot;&gt;&lt;a href=&quot;#准备&quot; class=&quot;headerlink&quot; title=&quot;准备&quot;&gt;&lt;/a&gt;准备&lt;/h2&gt;&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;耀波师兄曾经给过我一个文档，记录了早年间，他在树莓派的命令行下认证DLUT的解决方案，其思路基本是抓包再重放。运</summary>
      
    
    
    
    <category term="开发和调试笔记" scheme="http://bye-lemon.github.io/categories/%E5%BC%80%E5%8F%91%E5%92%8C%E8%B0%83%E8%AF%95%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="DLUT" scheme="http://bye-lemon.github.io/tags/DLUT/"/>
    
  </entry>
  
  <entry>
    <title>《高级操作系统》复习纲要</title>
    <link href="http://bye-lemon.github.io/post/b346/"/>
    <id>http://bye-lemon.github.io/post/b346/</id>
    <published>2021-01-12T08:07:58.000Z</published>
    <updated>2021-01-17T05:45:09.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、分布式系统概述"><a href="#一、分布式系统概述" class="headerlink" title="一、分布式系统概述"></a>一、分布式系统概述</h2><hr><h3 id="1-什么是分布式系统？"><a href="#1-什么是分布式系统？" class="headerlink" title="1. 什么是分布式系统？"></a>1. 什么是分布式系统？</h3><ul><li>分布式系统是若干独立计算机的集合，它们对于用户来说就像一个系统。</li><li>分布式系统屏蔽系统中种类各异的计算机和网络，常常通过一个软件层（中间件）组织起来。</li><li>常见的分布式系统有：大学或公司的工作站网络、支持订单自动处理的工作流系统以及万维网。</li></ul><h3 id="2-分布式系统中透明性的种类、定义。"><a href="#2-分布式系统中透明性的种类、定义。" class="headerlink" title="2. 分布式系统中透明性的种类、定义。"></a>2. 分布式系统中透明性的种类、定义。</h3><ul><li>分布式系统的透明性</li></ul><div class="table-container"><table><thead><tr><th style="text-align:center">透明性</th><th style="text-align:center">描述</th></tr></thead><tbody><tr><td style="text-align:center">访问</td><td style="text-align:center">隐藏数据表示形式以及访问方式的不同</td></tr><tr><td style="text-align:center">位置</td><td style="text-align:center">隐藏数据所在位置</td></tr><tr><td style="text-align:center">迁移</td><td style="text-align:center">隐藏资源是否已移动到另一个位置</td></tr><tr><td style="text-align:center">重定位</td><td style="text-align:center">隐藏资源是否在使用中已移动到另一个位置</td></tr><tr><td style="text-align:center">复制</td><td style="text-align:center">隐藏资源是否已被复制</td></tr><tr><td style="text-align:center">并发</td><td style="text-align:center">隐藏资源是否由若干相互竞争的用户共享</td></tr><tr><td style="text-align:center">故障</td><td style="text-align:center">隐藏资源的故障和恢复</td></tr><tr><td style="text-align:center">持久性</td><td style="text-align:center">隐藏资源（软件）位于内存里或在磁盘上</td></tr></tbody></table></div><h3 id="3-分布式系统中的拓展技术有哪些？"><a href="#3-分布式系统中的拓展技术有哪些？" class="headerlink" title="3. 分布式系统中的拓展技术有哪些？"></a>3. 分布式系统中的拓展技术有哪些？</h3><ul><li><p>分布式系统的拓展技术</p><ul><li>隐藏通信等待时间<ul><li>异步通信</li><li>减少通信量</li></ul></li><li>分布技术：分割组件、分散到系统中（DNS、WWW）</li><li>复制技术：多拷贝</li></ul></li><li><p>减少通信量的实例：将由服务器检验表单改成由客户端检验表单；</p></li><li>分布技术的实例：将DNS名字空间划分为区；</li><li>复制技术的实例：<ul><li>复制：增加可用性，有助于负载均衡；</li><li>缓存：在访问资源的客户周围制作资源备份；</li><li>复制技术带来了一致性问题。</li></ul></li></ul><h2 id="二、体系结构"><a href="#二、体系结构" class="headerlink" title="二、体系结构"></a>二、体系结构</h2><hr><h3 id="1-客户端-服务器模型"><a href="#1-客户端-服务器模型" class="headerlink" title="1. 客户端-服务器模型"></a>1. 客户端-服务器模型</h3><ul><li><p>如下图所示，在C-S模型中，<strong>服务器（Server）</strong>指实现某个特定服务的进程；<strong>客户端（Client）</strong>指向服务器请求服务的进程；客户端-服务器之间的一般交互形式是<strong>请求/回复（Request/Reply）</strong>。</p><p><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20210110163857.png" alt="image-20210110163857420"></p></li><li><p>在局域网内，可以建立<strong>无连接的协议</strong>，高效，但会受传输故障的影响；在广域网上，可以建立<strong>基于连接的协议</strong>，性能相对较低，但可靠。</p></li><li><p>在Client上，应用程序常常被组织为三个层次：<strong>用户界面层</strong>、<strong>处理层</strong>和<strong>数据层</strong>。</p><ul><li><strong>用户界面层</strong>：用户交互所需的一切；</li><li><strong>处理层</strong>：应用程序核心功能；</li><li><strong>数据层</strong>：操作数据或文件系统，保持一致性；</li></ul></li></ul><p><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20210110164057.png" alt="image-20210110164057779"></p><h3 id="2-多层体系结构"><a href="#2-多层体系结构" class="headerlink" title="2. 多层体系结构"></a>2. 多层体系结构</h3><ul><li><p>在常见的C-S模型中（<strong>物理两层体系结构</strong>），客户端和服务器的界限划分有多种可能：</p><p><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20210110164249.png" alt="image-20210110164249737"></p></li><li><p>同时，服务器也可以充当客户端的角色，比如下面这一应用场景（<strong>物理三层体系结构</strong>）：</p><p><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20210110164346.png" alt="image-20210110164346045"></p></li></ul><h2 id="三、分布式进程管理"><a href="#三、分布式进程管理" class="headerlink" title="三、分布式进程管理"></a>三、分布式进程管理</h2><hr><h3 id="1-进程与线程的比较。"><a href="#1-进程与线程的比较。" class="headerlink" title="1. 进程与线程的比较。"></a>1. 进程与线程的比较。</h3><div class="table-container"><table><thead><tr><th style="text-align:center">比较项</th><th style="text-align:center">进程</th><th style="text-align:center">线程</th></tr></thead><tbody><tr><td style="text-align:center">地址空间和资源</td><td style="text-align:center">进程间相互独立</td><td style="text-align:center">同一进程下的线程共享</td></tr><tr><td style="text-align:center">通信</td><td style="text-align:center">进程间通信通过IPC进行</td><td style="text-align:center">线程间通信可直接读写进程的数据段，但需要同步和互斥技术保证一致性</td></tr><tr><td style="text-align:center">调度</td><td style="text-align:center">进程上下文切换慢</td><td style="text-align:center">线程上下文切换快</td></tr></tbody></table></div><ul><li>进程与线程的总结：<ul><li>多线程能提高性能；</li><li>线程不像进程那样彼此隔离，并受到系统自动提供的保护，因此多线程应用程序开发需要付出更多努力。</li></ul></li></ul><h3 id="2-多线程服务器的优点。"><a href="#2-多线程服务器的优点。" class="headerlink" title="2. 多线程服务器的优点。"></a>2. 多线程服务器的优点。</h3><ul><li>显著简化服务器代码；</li><li>使得应用并行技术开发高性能服务器变得更加容易；</li><li>保留顺序处理的思路，使用阻塞性的系统调用以提升性能；</li></ul><h3 id="3-代码迁移的动机有哪些？"><a href="#3-代码迁移的动机有哪些？" class="headerlink" title="3. 代码迁移的动机有哪些？"></a>3. 代码迁移的动机有哪些？</h3><ul><li><strong>实现负载均衡</strong>：将进程从负载重的系统迁移到负载轻的系统，从而改善整体性能；</li><li><strong>改善通信性能</strong>：交互密集的进程可迁移到同一个节点执行以减少通信开销；当进程要处理的数据量较大时，最好将进程迁移到数据所在的节点；</li><li><strong>保障可用性</strong>：需长期运行的进程可能因为当前运行机器要关闭而需要迁移；</li><li><strong>使用特殊功能</strong>：可以充分利用特定节点上独有的硬件或软件功能。</li></ul><h3 id="4-进程对资源以及资源对机器的绑定"><a href="#4-进程对资源以及资源对机器的绑定" class="headerlink" title="4. 进程对资源以及资源对机器的绑定"></a>4. 进程对资源以及资源对机器的绑定</h3><ul><li>进程对资源的绑定类型有三种，由强到弱分别是<strong>按标志符</strong>、<strong>按值</strong>和<strong>按类型</strong>。</li><li>资源对机器的绑定类型有三种，由强到弱分别是<strong>紧固连接</strong>、<strong>附着连接</strong>和<strong>未连接</strong>。</li><li>在代码迁移时，对于资源的处理有四种形式：<ul><li><strong>MV</strong>：移动资源；</li><li><strong>GR</strong>：建立全局系统范围内引用；</li><li><strong>CP</strong>：复制资源；</li><li><strong>RB</strong>：将进程重新绑定到本地同类型资源。</li></ul></li><li>相应的，在每一种绑定类型下可以进行的操作如下表所示：</li></ul><div class="table-container"><table><thead><tr><th></th><th>未连接</th><th>附着连接</th><th>紧固连接</th></tr></thead><tbody><tr><td>按标志符</td><td>MV、GR</td><td>GR、MV</td><td>GR</td></tr><tr><td>按值</td><td>CP、MV、GR</td><td>GR、CP</td><td>GR</td></tr><tr><td>按类型</td><td>RB、MV、CP</td><td>RB、GR、CP</td><td>RB、GR</td></tr></tbody></table></div><h2 id="四、分布式系统通信"><a href="#四、分布式系统通信" class="headerlink" title="四、分布式系统通信"></a>四、分布式系统通信</h2><hr><h3 id="1-远程过程调用"><a href="#1-远程过程调用" class="headerlink" title="1. 远程过程调用"></a>1. 远程过程调用</h3><ul><li><p><strong>远程过程调用（Remote Procedure Call）</strong>是分布式系统通信处理的事实标准，实现消息传输的透明性，其原理如下图所示。</p><p><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20210110194300.png" alt="image-20210110194300220"></p></li><li><p>远程过程调用的步骤如下：</p><ol><li>客户过程以正常的方式调用客户存根；</li><li>客户存根生成一个消息，然后调用本地操作系统；</li><li>客户端操作系统将消息发送给远程操作系统；</li><li>远程操作系统将消息交给服务器存根；</li><li>服务器存根将参数提取出来，然后调用服务器；</li><li>服务器执行要求的操作，操作完成后将结果返回给服务器存根；</li><li>服务器存根将结果打包成一个消息，然后调用本地操作系统；</li><li>服务器操作系统将含有结果的消息发送回客户端操作系统；</li><li>客户端操作系统将消息交给客户存根；</li><li>客户存根将结果从消息中提取出来，返回给调用它的客户过程。</li></ol></li></ul><h3 id="2-持久通信与暂时通信的区别"><a href="#2-持久通信与暂时通信的区别" class="headerlink" title="2. 持久通信与暂时通信的区别"></a>2. 持久通信与暂时通信的区别</h3><ul><li>在持久通信中，通信双方不需要保持运行；在暂时通信中，通信系统只在发送者和接受者运行时存储消息。</li></ul><h3 id="3-同步通信与异步通信的区别"><a href="#3-同步通信与异步通信的区别" class="headerlink" title="3. 同步通信与异步通信的区别"></a>3. 同步通信与异步通信的区别</h3><ul><li>在同步通信中，客户端需要自我阻塞等待服务器的回复；在异步通信中，客户端不等待，立即执行其他程序。</li></ul><h3 id="4-消息通信的类型"><a href="#4-消息通信的类型" class="headerlink" title="4. 消息通信的类型"></a>4. 消息通信的类型</h3><ul><li><p><strong>持久异步通信</strong>和<strong>持久同步通信</strong>：</p><p><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20210110215033.png" alt="image-20210110215033630"></p></li><li><p><strong>暂时异步通信</strong>和<strong>基于接收的暂时同步通信</strong></p><p><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20210110215539.png" alt="image-20210110215539655"></p></li><li><p><strong>基于交付的暂时同步通信</strong>和<strong>基于响应的暂时同步通信</strong></p><p><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20210110215719.png" alt="image-20210110215719436"></p></li></ul><h3 id="5-多播通信"><a href="#5-多播通信" class="headerlink" title="5. 多播通信"></a>5. 多播通信</h3>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、分布式系统概述&quot;&gt;&lt;a href=&quot;#一、分布式系统概述&quot; class=&quot;headerlink&quot; title=&quot;一、分布式系统概述&quot;&gt;&lt;/a&gt;一、分布式系统概述&lt;/h2&gt;&lt;hr&gt;
&lt;h3 id=&quot;1-什么是分布式系统？&quot;&gt;&lt;a href=&quot;#1-什么是分布式系</summary>
      
    
    
    
    
    <category term="DUT" scheme="http://bye-lemon.github.io/tags/DUT/"/>
    
    <category term="备考" scheme="http://bye-lemon.github.io/tags/%E5%A4%87%E8%80%83/"/>
    
    <category term="操作系统" scheme="http://bye-lemon.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>自动驾驶中间件Cyber RT中的实时通信机制简述</title>
    <link href="http://bye-lemon.github.io/post/89b2/"/>
    <id>http://bye-lemon.github.io/post/89b2/</id>
    <published>2020-12-30T13:04:09.000Z</published>
    <updated>2021-08-18T06:29:00.242Z</updated>
    
    <content type="html"><![CDATA[<h3 id="无人驾驶系统与Cyber-RT"><a href="#无人驾驶系统与Cyber-RT" class="headerlink" title="无人驾驶系统与Cyber RT"></a>无人驾驶系统与Cyber RT</h3><ul><li><p>无人驾驶是汽车自动化研究的一个问题，汽车自动化是一个已经有着百年研究历史课题。根据其自动化的实现程度，美国汽车工程师协会拟定了<strong>SAEJ3016标准</strong>，将其分成了六个等级，记做L0~L5。</p></li><li><p>现在我们看到的特斯拉以及百度等大部分商用无人车的研究都属于L4级别的范畴上。一个典型的L4级别的无人驾驶系统通常包括三个部分<strong>用户端</strong>、<strong>算法</strong>和<strong>云端</strong>。其中，用户端即是汽车及其附加的各类传感设备以及其上搭载的运算平台。在这个平台上运行了若干应用程序，机器人操作系统就是其中之一。</p></li><li><p><strong>机器人操作系统（Robot Operating System，ROS）</strong>是一个以BSD协议开源的中间件，提供了一系列程序库和工具包来帮助构建机器人软件系统，提供了硬件抽象、设备驱动、库函数、可视化、消息传递和软件包管理等诸多功能。ROS为无人驾驶系统的构建提供了极大地便利，具体的，包括了以下三个部分：</p><ul><li><p><strong>通信系统</strong>：ROS是一个分布式的松耦合系统，基于Socket实现了一个Publisher/Subscriber的节点间通信。</p></li><li><p><strong>框架和工具</strong>：ROS提供了基于消息的用户库和通信层，开发者只需要关注消息处理的算法本身而无需考虑其调度。</p></li><li><p><strong>生态</strong>：ROS拥有丰富的社区生态，许多传感器的驱动以及常用算法都有社区实现。</p></li></ul></li><li><p>然而ROS也有不适合自动驾驶之处，ROS上的各个节点之间的调度是公平的，但自动驾驶任务中，算法节点的运行需要有一定的逻辑，此外ROS还有通信开销等一系列问题，因而，自动驾驶需要一个面向该特定场景下的专用系统。</p></li><li><p>面向上述ROS所存在的问题，百度基于ROS开发了一个面向自动驾驶任务的通信中间件Cyber RT，面对ROS存在的若干问题，Cyber RT使用<strong>有向无环图</strong>描述任务，并依次创建任务，按照预设的调度配置和任务配置将任务分配到处理器中，再由传感器数据驱动任务运转，同时，将处理器调度单位由进程、线程改成了<strong>协程</strong>，从而将调度、任务从内核空间转移到了用户空间，实现了与业务逻辑的更紧密结合，Cyber RT的整体架构如下图所示：<br><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20210109113942.png" alt=""></p></li></ul><h3 id="Cyber-RT中的多线程通信模块：Transport"><a href="#Cyber-RT中的多线程通信模块：Transport" class="headerlink" title="Cyber RT中的多线程通信模块：Transport"></a>Cyber RT中的多线程通信模块：Transport</h3><ul><li><p>在Cyber RT的代码架构中Transport模块负责完成多进程通信，其基本的类有：</p><ul><li><p><code>Segment</code>类负责管理一段共享存储空间，通过Acquire-Release的机制，让其他类可以在线程安全的前提下获取Shared Memory中的对象；</p></li><li><p><code>Block</code>是最基本的数据存储单元，其中存储了各个Channel上的数据，他也是其他类读写的数据单元，在一个<code>Segment</code>中可以有多个<code>Block</code>；</p></li><li><p><code>State</code>用于管理<code>Segment</code>中的内部状态，以便在多个进程上做到状态的同步；</p></li><li><p><code>Receiver</code>是一个抽象类，它是<code>ShmReceiver</code>、<code>IntraReceiver</code>、<code>RtpsReceiver</code>的基类，其负责监听特定的Channel，当Channel上有数据时，调用相应的回调；</p></li><li><p><code>Transmitter</code>是一个抽象类，它是<code>ShmTransmitter</code>、<code>IntraTransmitter</code>、<code>RtpsTransmitter</code>的基类，其负责将数据发送到指定的Channel上，并通知相应的Notifier数据有更新；</p></li><li><p><code>Dispatcher</code>用于管理所有的Receiver对数据的读取，当有新数据时，就调用Receiver注册的回调，向Receiver分发新数据；</p></li><li><p><code>Notifier</code>用于发出有新数据时的提醒，与<code>Dispatcher</code>共同完成Receiver对数据的收取；</p><ul><li><p><code>ConditionNotifier</code>是一种基于Conditional Variable的<code>Notifier</code>，供基于Shared Memory的通信使用；</p></li><li><p><code>MulticastNotifier</code>是一种基于Socket Multicast的<code>Notifier</code>，供基于RTPS的通信使用；</p></li></ul></li><li><p><code>ReadableInfo</code>是一组包含了发送者信息、Channel信息和Block信息的结构体，由<code>Notifier</code>在接收到了新数据之后发送；</p></li><li><p><code>ListenHandler</code>是一种增强的回调；</p></li><li><p><code>Signal</code>、<code>Connect</code>、<code>Slot</code>参者构成了一种通用的回调机制；</p></li></ul></li></ul><h3 id="基于共享存储空间的多进程通信"><a href="#基于共享存储空间的多进程通信" class="headerlink" title="基于共享存储空间的多进程通信"></a>基于共享存储空间的多进程通信</h3><ul><li><p>基于共享存储空间（Shared Memory）的多进程通信机制在Cyber RT中主要由<code>ShmDispatcher</code>、<code>ShmReceiver</code>、<code>ShmTransmitter</code>、<code>Segment</code>、<code>NotifierBase</code>这几个模块完成。其中<code>ShmDispatcher</code>、<code>ShmReceiver</code>、<code>ShmTransmitter</code>均为其基类基于Shared Memory的一种实现。</p></li><li><p>共享内存，即允许两个不相关的进程访问同一个逻辑内存，这一方式是两个运行中的进程之间共享和传递数据的一种非常高效的方式。不同的进程将同一段物理内存映射到各自不同的地址空间上，各个进程均可以访问共享内存中的地址，一个进程对共享内存的改动会立即影响到访问该共享内存的其他进程，十分高效。<br><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20210109174216.png" alt=""></p></li><li><p>不过共享内存并不包含同步机制，因此为保障线程安全，需要使用额外的机制来提供同步，例如条件变量。条件变量为线程提供了聚合的场所，当某一个线程修改这个变量使其满足其他线程继续往下进行的条件之后，其他线程将收到该条件已经发生改变的信号。条件变量与锁共同使用个可以使线程以一种无竞争的方式等待任意条件的发生，在Cyber RT对于基于共享内存的多进程通信的实现中，就应用了这一机制。</p></li><li><p>在Shared Memory的实现方式下，一次由<code>Transmitter</code>发送数据到<code>Receiver</code>中的过程如下：</p><ol><li><p>应用调用<code>ShmTransmitter</code>中的<code>Transmit</code>接口发送数据；</p></li><li><p><code>ShmTransmitter</code>从相应的<code>Segment</code>中获取可写的<code>Block</code>并为其上写锁，将数据序列化后写入<code>Block</code>，释放写锁，创建一个<code>ReadableInfo</code>结构体相关信息，并将其交付<code>Notifier</code>；</p></li><li><p><code>Notifier</code>通过操作条件变量让<code>Listen</code>返回<code>true</code>；</p></li><li><p><code>ShmTransmitter</code>不断轮询<code>Notifier</code>的消息，监听到<code>Listen</code>返回<code>true</code>之后，解析<code>ReadableInfo</code>结构体，在对应的<code>Segment</code>上请求读锁，将相应<code>Block</code>的数据反序列化成对象，而后，释放读锁。</p></li><li><p><code>ListenHandler</code>找到需要的调用的回调并调用。</p></li></ol></li><li><p>Intra模式是Transport模块下的另一种实现，其用于进程内通信而非多进程通信，该模式也派生了相应的<code>IntraDispatcher</code>、<code>IntraReceiver</code>、<code>IntraTransmitter</code>来完成通信任务，其实现与基于Shared Memory的实现类似，区别在于去除了锁机制保护。</p></li></ul><h3 id="基于RTPS的多进程通信"><a href="#基于RTPS的多进程通信" class="headerlink" title="基于RTPS的多进程通信"></a>基于RTPS的多进程通信</h3><ul><li><p>基于实时发布订阅（Real-Time Publish Subscribe）的多进程通信机制，基于RTPS的多进程通信也实现了相应的<code>RtpsDispatcher</code>、<code>RtpsReceiver</code>、<code>RtpsTransmitter</code>来完成相应的功能。Cyber RT中的RTPS通信是基于<code>fastrtps</code>库来完成的，因此该模式下有几个特有的类：</p><ul><li><p><code>UnderlayMessage</code>、<code>UnderlayMessageType</code>、<code>AttributesFiller</code>、<code>QosProfileConf</code>是<code>fastrtps</code>所要求的消息类型和配置文件的封装；</p></li><li><p><code>SubListener</code>是兼具了<code>Subscriber</code>和<code>Listener</code>两种作用的一个模块，负责在<code>eprosima::fastrtps::Subscriber</code>受到新的消息时，调用对应的回调。</p></li></ul></li><li><p>RTPS是一种基于UDP等不可靠传输进行的best-effort和reliable的发布-订阅通信，具有容错、可扩展、即插即用连接、模块化、可伸缩、类型安全等特点，其包括以下四个模块：</p><ul><li><p><strong>结构模块</strong>：定义通信端点，并将其映射到不同的DDS（数据分发服务）上；</p></li><li><p><strong>消息模块</strong>：定义数据端点间可以交换哪些消息以及如何构建这些消息；</p></li><li><p><strong>行为模块</strong>：定义了一组和合法交互，以及他们如何影响每一个通信端点；</p></li><li><p><strong>发现模块</strong>：定义了一组允许自动发现的内置端点；</p></li></ul></li><li><p>RTPS的结构模块是被设计用来实现DDS的实体，因而，每个DDS的实体都将被映射到一个RTPS实体，每一个实体都被关联到一个Domain上，域内是一组Participants的通信平面，其中包含了众多Writer和Reader，这两种类型的端点在通信平面中交换RTPS消息。<br><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20210109181152.png" alt=""></p></li><li><p>RTPS的消息模块用来定义Writer和Reader之间的信息交换的内容，由报头和子消息组成，RTPS定义的子消息一共有12类，其中常用的有如下三类子消息：</p><ul><li><p><strong>DATA</strong>：该子消息由Writer发送到Reader，其中包含了对属于Writer的数据对象的更改信息；</p></li><li><p><strong>HEARTBEAT</strong>：该子消息由Writer发送到Reader，其中包含了此时Writer可用的CacheChange；</p></li><li><p><strong>ACKNACK</strong>：该子消息由Reader发送到Writer，其中包含了其接受了那些更改，未收到哪些更改。</p></li></ul></li><li><p>RTPS的行为模块描述了在Writer和Reader间可能存在的合法的消息交换形式及其对Reader和Writer的状态修改，以确保不同实现间的互操作性；RTPS的发现模块定义了Participants获取Domain内其他Participants和Endpoints的存在和属性的协议，以保证不同实现间的即插即用连接。</p></li><li><p>在Cyber RT中，基于RTPS的多进程通信由于<code>fastrtps</code>的封装，其实现较为简单，通过<code>eprosima::fastrtps::Domain::createSubscriber()</code>和<code>eprosima::fastrtps::Domain::createPublisher()</code>完成注册，其余的事务均由<code>fastrtps</code>实现。</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;无人驾驶系统与Cyber-RT&quot;&gt;&lt;a href=&quot;#无人驾驶系统与Cyber-RT&quot; class=&quot;headerlink&quot; title=&quot;无人驾驶系统与Cyber RT&quot;&gt;&lt;/a&gt;无人驾驶系统与Cyber RT&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;无人驾驶是汽车自动</summary>
      
    
    
    
    <category term="开发和调试笔记" scheme="http://bye-lemon.github.io/categories/%E5%BC%80%E5%8F%91%E5%92%8C%E8%B0%83%E8%AF%95%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Apollo" scheme="http://bye-lemon.github.io/tags/Apollo/"/>
    
  </entry>
  
  <entry>
    <title>2020年电赛G题不完全实现方案</title>
    <link href="http://bye-lemon.github.io/post/45b8/"/>
    <id>http://bye-lemon.github.io/post/45b8/</id>
    <published>2020-11-10T07:53:23.000Z</published>
    <updated>2021-01-17T05:45:09.000Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://www.nuedc-training.com.cn/index/news/details/new_id/228">https://www.nuedc-training.com.cn/index/news/details/new_id/228</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://www.nuedc-training.com.cn/index/news/details/new_id/228&quot;&gt;https://www.nuedc-training.com.cn/index/news/details/new_id/228</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>如何为Hexo博客构建一个简单的全文搜索引擎</title>
    <link href="http://bye-lemon.github.io/post/9dd7/"/>
    <id>http://bye-lemon.github.io/post/9dd7/</id>
    <published>2020-11-10T07:52:52.000Z</published>
    <updated>2021-01-17T05:45:09.000Z</updated>
    
    
    
    
    
  </entry>
  
  <entry>
    <title>Apollo D-Kit 调试笔记（四）：基于Camera的自动驾驶</title>
    <link href="http://bye-lemon.github.io/post/3eb8/"/>
    <id>http://bye-lemon.github.io/post/3eb8/</id>
    <published>2020-11-10T07:49:24.000Z</published>
    <updated>2021-01-17T05:45:09.000Z</updated>
    
    
    
    
    <category term="开发和调试笔记" scheme="http://bye-lemon.github.io/categories/%E5%BC%80%E5%8F%91%E5%92%8C%E8%B0%83%E8%AF%95%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Apollo" scheme="http://bye-lemon.github.io/tags/Apollo/"/>
    
  </entry>
  
  <entry>
    <title>Apollo D-Kit 调试笔记（三）：基于Lidar的自动驾驶</title>
    <link href="http://bye-lemon.github.io/post/d69d/"/>
    <id>http://bye-lemon.github.io/post/d69d/</id>
    <published>2020-11-10T07:44:48.000Z</published>
    <updated>2021-01-17T05:45:09.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h3><hr><ul><li><p>在Apollo D-Kit中，各个传感器的坐标系定义如下图所示：<br><img src="https://github.com/ApolloAuto/apollo/raw/master/docs/D-kit/Lidar_Based_Auto_Driving/images/lidar_calibration_coordinate_system.jpg" alt="https://github.com/ApolloAuto/apollo/raw/master/docs/D-kit/Lidar_Based_Auto_Driving/images/lidar_calibration_coordinate_system.jpg"></p></li><li><p>基于Lidar的自动驾驶需要对Lidar相对于GNSS设备的外参进行标定，在此之前，需要先设定一个参数作为初始化参数，其中translation代表了以IMU坐标系为基坐标系，Lidar坐标系相对于IMU坐标系的一组平移变换，在默认的安装方式下，这一组默认参数可以被设定为</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">rotation:</span></span><br><span class="line">  <span class="attr">w:</span> <span class="number">0.7071</span></span><br><span class="line">  <span class="attr">x:</span> <span class="number">0.0</span></span><br><span class="line">  <span class="attr">y:</span> <span class="number">0.0</span></span><br><span class="line">  <span class="attr">z:</span> <span class="number">0.7071</span></span><br><span class="line"><span class="attr">translation:</span></span><br><span class="line">  <span class="attr">x:</span> <span class="number">0.0</span></span><br><span class="line">  <span class="attr">y:</span> <span class="number">0.38</span></span><br><span class="line">  <span class="attr">z:</span> <span class="number">1.33</span></span><br></pre></td></tr></table></figure></li></ul><h3 id="Lidar2GNSS标定"><a href="#Lidar2GNSS标定" class="headerlink" title="Lidar2GNSS标定"></a>Lidar2GNSS标定</h3><hr><h4 id="标定数据采集"><a href="#标定数据采集" class="headerlink" title="标定数据采集"></a>标定数据采集</h4><ul><li><p>在进行Lidar-GNSS标定之前，需要先寻找一块平坦的地面，确保场地中心8米范围内有诸如电线杆、车辆、建筑等轮廓清晰的静态障碍物，避免有大量行人等动态障碍物出现。</p></li><li><p>进入Docker内环境，启动Dreamview，在<code>--setup mode--</code>中选择模式<code>Dev Kit Debug</code>，并在<code>--vehicle--</code>中选择<code>Dev Kit</code>车型，在侧边栏中进入<code>Module Controller</code>页面，打开<code>GPS</code>、<code>Localization</code>和<code>Lidar</code>三个模块，在<code>cyber_monitor</code>中检查对应Channel下是否有数据，对应标准如前序环节所述。</p></li><li><p>如各个Channel的输出没有问题，打开<code>Recorder</code>模块开始记录数据，使用遥控器控制车辆缓慢绕“8”字至少5圈，这个过程中车辆的转弯半径应尽可能小，完成后，关闭<code>Recorder</code>模块，采集的驾驶数据将被保存在<code>apollo/data/bag</code>下，文件名是当前时间。</p></li></ul><h4 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h4><ul><li><p>使用<code>cp -r docs/Apollo_Fuel/examples/sensor_calibration ./</code>命令将数据抽取工作目录复制到工程根目录下，<code>sensor_calibration</code>目录中的每一个文件夹代表一个标定预处理任务，包括一个原始数据文件夹<code>records</code>、一个存放抽取后的数据的文件夹<code>extracted_data</code>以及一个配置文件<code>XXX_to_XXXX.config</code>，在本任务重，我们只需要其中的<code>lidar_to_gnss</code>文件夹。</p></li><li><p>将<code>apollo/data/bag</code>目录下采集到的数据拷贝到<code>sensor_calibration/lidar_to_gnss/records</code>，修改<code>lidar_to_gnss.config</code>文件，修改<code>records</code>字段下的<code>record_path</code>一项对应的路径为存储记录文件的路径，该路径下须有形如<code>******.record.00001</code>的记录文件，记录下<code>io_config</code>字段下的<code>output_path</code>一项对应的路径，这将是抽取后数据的保存路径，需注意，这里的路径需要时自<code>/apollo/</code>始的绝对路径。</p></li><li><p>使用<code>cd /apollo/modules/tools/sensor_calibration</code>切换工作目录，运行<code>python extract_data.py --config /apollo/sensor_calibration/lidar_to_gnss/lidar_to_gnss.config</code>命令，从记录数据中抽取出标定需要的数据，等待出现<code>Data extraction is completed successfully!</code>字样，抽取工作完成。运行过抽取命令后的目录结构如下所示</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">lidar_to_gnss&#x2F;</span><br><span class="line">├── extracted_data</span><br><span class="line">│   ├── lidar_to_gnss-2020-10-27-20-26</span><br><span class="line">│   │   ├── lidar16_to_gnss_calibration</span><br><span class="line">│   │   │   ├── _apollo_localization_pose</span><br><span class="line">│   │   │   ├── _apollo_sensor_lidar16_PointCloud2</span><br><span class="line">│   │   │   └── sample_config.yaml</span><br><span class="line">│   │   └── tmp</span><br><span class="line">│   │       ├── _apollo_localization_pose</span><br><span class="line">│   │       ├── _apollo_sensor_lidar16_PointCloud2</span><br><span class="line">│   │       └── lidar16_sample_config.yaml</span><br><span class="line">│   └── readme.txt</span><br><span class="line">├── lidar_to_gnss.config</span><br><span class="line">└── records</span><br><span class="line">    ├── 20200723180717.record.00000</span><br><span class="line">    └── readme.txt</span><br></pre></td></tr></table></figure></li><li><p>编辑<code>extracted_data/lidar_to_gnss-XXXX-XX-XX-XX-XX/sample_config.yaml</code>文件，修改<code>transform</code>字段下的<code>translation</code>的值，将其修改为前文所述的初始外参。</p></li></ul><h4 id="云标定"><a href="#云标定" class="headerlink" title="云标定"></a>云标定</h4><ul><li><p>在BOS的Bucket中创建一个名为<code>sensor_calibration</code>的文件夹存放原始数据，在建立一个名为<code>out</code>的文件夹存放输出的标定结果，将<code>lidar16_to_gnss_calibration</code>文件夹完整的上传至Bucket中<code>sensor_calibration</code>文件夹下，需要注意的是，目前BOS不支持文件夹上传，所以需要逐个文件夹的建立，再上传内部文件，同一次上传最多可以支持300个文件。</p></li><li><p>上传完成之后，打开Apollo云服务，在Apollo Fuel中新建一个感知标定类型的任务，输入数据路径为<code>sensor_calibration</code>，输出数据路径为<code>out</code>，然后将任务提交，标定过程大约需要持续1小时，完成后会收到邮件提醒。</p></li><li><p>标定完成之后，标定结果会作为附件发送到邮箱里，附件名称为<code>velodyne16_novatel_extrinsics_example.yaml</code>，同时在BOS的输出目录下会生成一个层次如下的目录：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">out&#x2F;</span><br><span class="line">└── 20201104145626622504</span><br><span class="line">    └── lidar16_to_gnss_calibration</span><br><span class="line">        ├── results</span><br><span class="line">        │   ├── tmp</span><br><span class="line">        │   │   └── lidar</span><br><span class="line">        │   │       ├── final_clouds</span><br><span class="line">        │   │       ├── init_clouds</span><br><span class="line">        │   │       ├── raw_clouds</span><br><span class="line">        │   │       ├── raw_pose</span><br><span class="line">        │   │       ├── lidar_result.pcd</span><br><span class="line">        │   │       └── lidar16_result_rgb.pcd</span><br><span class="line">        │   └── lidar16_novaltel_extrinsic.yaml</span><br><span class="line">        └── lidar_to_gnss_calibration_config.yaml</span><br></pre></td></tr></table></figure></li><li><p>对于标定结果的验证可以下载其中的<code>lidar16_result_rgb.pcd</code>文件，使用点云查看工具打开，比较推荐的工具是开源软件CloudCompare，其官网为<a href="http://www.cloudcompare.org/">http://www.cloudcompare.org/</a>，打开点云后，红色的线条代表驾驶的轨迹，如果周围的障碍物清晰锐利、边缘整齐，说明标定成功。<br><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20201112172646.png" alt=""></p></li></ul><h4 id="更新配置文件"><a href="#更新配置文件" class="headerlink" title="更新配置文件"></a>更新配置文件</h4><ul><li>如果标定成功，使用邮件附件<code>velodyne16_novatel_extrinsics_example.yaml</code>中的<code>rotation</code>值和<code>translation</code>值替代工程目录中<code>modules/calibration/data/dev_kit/lidar_params/velodyne16_novatel_extrinsics.yaml</code>中对应的值以应用标定数据。</li></ul><h3 id="虚拟车道线生成"><a href="#虚拟车道线生成" class="headerlink" title="虚拟车道线生成"></a>虚拟车道线生成</h3><hr><h4 id="数据采集"><a href="#数据采集" class="headerlink" title="数据采集"></a>数据采集</h4><ul><li><p>将Apollo D-Kit驾驶至将进行自动驾驶的区域，进入Docker内环境，打开Dreamview，在<code>--setup mode--</code>中选择模式<code>Dev Kit Debug</code>，并在<code>--vehicle--</code>中选择<code>Dev Kit</code>车型，在侧边栏中进入<code>Module Controller</code>页面，打开<code>GPS</code>、<code>Localization</code>和<code>Lidar</code>三个模块，另启动两个终端，分别进入Docker内环境并运行以下两条命令，启动相应Channel的Publisher。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python modules/tools/sensor_calibration/ins_stat_publisher.py</span><br><span class="line">python modules/tools/sensor_calibration/odom_publisher.py</span><br></pre></td></tr></table></figure></li><li><p>检查<code>/apollo/localization/pose</code>、<code>/apollo/sensor/gnss/odometry</code>、<code>/apollo/sensor/gnss/ins_stat</code>、<code>/apollo/sensor/lidar16/compensator/PointCloud2</code>四个Channel上的输出是否正常，如若正常输出，可以开始采集必要的数据。</p></li><li><p>打开<code>Recorder</code>模块，驾驶车辆沿计划实施自动驾驶的道路中央运行至路段终点，关闭<code>Recorder</code>模块，在<code>apollo/data/bag</code>中找到对应的记录以备后续使用，需要注意的是，虚拟车道线的生成环节中，提交的数据包不能超过5GB。</p></li></ul><h4 id="提交云服务"><a href="#提交云服务" class="headerlink" title="提交云服务"></a>提交云服务</h4><ul><li><p>打开BOS中的Bucket，建立两个文件夹，用于存储原始数据的<code>virtual_lane</code>和用于存储生成的虚拟车道线的<code>lane_out</code>，将上述文件夹下形如<code>******.record.00001</code>的记录文件上传至BOS上的<code>virtual_lane</code>目录下，再将上一个环节中邮箱里收到的外参文件重命名为<code>velodyne16_novatel_extrinsics_example.yaml</code>，也上传到这一目录下。</p></li><li><p>打开Apollo云服务，在Apollo Fuel中提交虚拟车道线任务，输入数据路径为<code>virtual_lane</code>，输出数据路径为<code>lane_out</code>，区域编号为<code>51</code>（此为大连地区的UTM投影编号），雷达类型为<code>lidar16</code>，车道宽度设置为理想的虚拟车道线宽度，譬如<code>2.2</code>，额外ROI扩展是虚拟车道线与实际车道线边缘的距离，为了安全，虚拟车道线可能设置的比实际宽度更窄，但是对于不在虚拟车道线范围内的环境也要建立感知，这就需要设定这一参数。设定完成后，提交任务。</p></li></ul><h4 id="应用虚拟车道线"><a href="#应用虚拟车道线" class="headerlink" title="应用虚拟车道线"></a>应用虚拟车道线</h4><ul><li><p>在提交标定任务的约4-5小时后，预留的邮箱中会收到一条邮件提醒，代表标定工作已经完成，生成的地图将在BOS中的<code>lane_out</code>目录下，将其下载下来，重命名为相应的名字并拷贝到<code>/apollo/modules/map/data/</code>下，路径即可生效。</p></li><li><p><strong>（Optional）</strong>由于BOS网页版不支持文件夹的下载，可以在<a href="https://cloud.baidu.com/doc/BOS/s/lk4tnbkrm">https://cloud.baidu.com/doc/BOS/s/lk4tnbkrm</a>中下载BOS桌面版，使用Access Key和Secret Access Key进行登录，在BOS桌面端里进行文件夹的下载。</p></li></ul><h3 id="自动驾驶实验"><a href="#自动驾驶实验" class="headerlink" title="自动驾驶实验"></a>自动驾驶实验</h3><hr><h4 id="感知适配"><a href="#感知适配" class="headerlink" title="感知适配"></a>感知适配</h4><ul><li><p>在进行感知适配之前，需要先修改<code>modules/common/data/global_flagfile.txt</code>，为其添加一行<code>--half_vehicle_width=0.43</code>，进入Docker内环境使用<code>bash apollo.sh build_opt_gpu</code>命令重新编译工程。</p></li><li><p>启动Dreamview，在<code>--setup mode--</code>中选择模式<code>Dev Kit Debug</code>，并在<code>--vehicle--</code>中选择<code>Dev Kit</code>车型，并选择生成的地图，在侧边栏中进入<code>Module Controller</code>页打开<code>Canbus</code>、<code>GPS</code>、<code>Localization</code>、<code>Transform</code>、<code>Lidar</code>以及<code>Lidar Preception</code>六个模块，检查<code>tf</code>、<code>tf_static</code>、<code>/apollo/localization/pose</code>、<code>/apollo/sensor/lidar16/PointCloud2</code>、<code>/apollo/sensor/lidar16/Scan</code>、<code>/apollo/sensor/lidar16/compensator/PointCloud2</code>、<code>/apollo/perception/obstacles</code>等Channel上是否有输出。</p></li><li><p>在Dreamview的界面中观察，界面中是否有障碍物出现。在Dreamviewer中，绿色代表车辆、黄色代表行人、青色代表自行车，带有箭头的线代表对目标运动方向和归集的预测，目标的上方是它的ID、速度以及Apollo为他执行的策略，如IGNORE或CAUTION等。</p></li></ul><h4 id="规划适配"><a href="#规划适配" class="headerlink" title="规划适配"></a>规划适配</h4><ul><li><p>在感知适配的基础上再在<code>Module Controller</code>页打开<code>Planning</code>、<code>Prediction</code>、<code>Routing</code>、<code>Control</code>模块。</p></li><li><p>再在<code>Route Editing</code>页中点击<code>Add Point of Interest</code>，然后在车道线上点击一个点作为终点，点击<code>Send Routing Request</code>发送路径规划请求。在这一页面中，按住鼠标右键可以拖动地图，使用鼠标滚轮可以对地图进行放缩，点击鼠标左键可以添加一个PoI点。</p></li><li><p>此时，应看到一条红色的细线，标记着从当前位置到终点位置的路径，蓝色的粗线，代表着当前一个局部的具体规划，在终点处有一个红色的平面标志停止，当有行人出现在规划路径上时，同样会出现停止标志，并重新规划路径。</p></li></ul><h4 id="自动驾驶"><a href="#自动驾驶" class="headerlink" title="自动驾驶"></a>自动驾驶</h4><ul><li><p>将<code>--setup mode--</code>切换为<code>Dev Kit Closeloop</code>，启动上述感知适配和规划适配中启动的各个模块，待模块完全启动后，发送路径规划请求，遥控器放权，在<code>Tasks</code>页面中点击<code>Start Auto</code>，此时，应看到车辆按照所规划的路径自动驾驶，此时可以观察界面中不断replan的轨迹和车辆的实时驾驶状态是否科学安全，如有异常，随时使用遥控器接管车辆。</p></li><li><p>到达终点后，车辆会自动停止，此时先使用遥控器接管车辆，发送下一个目的地点，或结束实验。</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;准备工作&quot;&gt;&lt;a href=&quot;#准备工作&quot; class=&quot;headerlink&quot; title=&quot;准备工作&quot;&gt;&lt;/a&gt;准备工作&lt;/h3&gt;&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;在Apollo D-Kit中，各个传感器的坐标系定义如下图所示：&lt;br&gt;&lt;img src=&quot;ht</summary>
      
    
    
    
    <category term="开发和调试笔记" scheme="http://bye-lemon.github.io/categories/%E5%BC%80%E5%8F%91%E5%92%8C%E8%B0%83%E8%AF%95%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Apollo" scheme="http://bye-lemon.github.io/tags/Apollo/"/>
    
  </entry>
  
  <entry>
    <title>Apollo D-Kit 调试笔记（二）：动力学标定与循迹验证</title>
    <link href="http://bye-lemon.github.io/post/d2b3/"/>
    <id>http://bye-lemon.github.io/post/d2b3/</id>
    <published>2020-10-22T12:41:29.000Z</published>
    <updated>2021-01-17T05:45:09.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h3><hr><h4 id="Apollo-Fuel服务的申请"><a href="#Apollo-Fuel服务的申请" class="headerlink" title="Apollo Fuel服务的申请"></a>Apollo Fuel服务的申请</h4><ul><li><p>打开<a href="https://login.bce.baidu.com/?redirect=https%3A%2F%2Fconsole.bce.baidu.com%2F">https://login.bce.baidu.com/?redirect=https%3A%2F%2Fconsole.bce.baidu.com%2F</a>登录BOS，进入控制台后点击<code>对象存储BOS</code>，在页面中开通对象存储服务，并创建一个Bucket，选择私有、按使用流量计费。创建完成之后，记录下Bucket名称、地域，而后，点击右上角<code>Access Key</code>按钮，在弹出的页面中记录下<code>Ak</code>和<code>SK</code>。</p></li><li><p>打开<a href="http://bce.apollo.auto">http://bce.apollo.auto</a>，在左侧选择“帐号状态”，点击“Apollo Fuel”下方的蓝色超链接“这里”，在弹出的模态框中输入对应的信息，包括车辆自身的信息和上述BOS服务的信息，提交确认，等待商务人员审核。</p></li></ul><h4 id="可能用到的软件"><a href="#可能用到的软件" class="headerlink" title="可能用到的软件"></a>可能用到的软件</h4><ul><li><p>循迹实验中，Apollo D-Kit的行驶数据会被保存在本地的一个CSV文件中，为了方便对其中的数据进行可视化分析，可能会使用到Matlab和QGIS，Matlab可以用来可视化速度、油门大小等信息，QGIS可以将GPS信息进行可视化。QGIS是一个开源软件的，其下载地址如下：</p><blockquote><p>QGIS Project：<a href="https://www.qgis.org/zh-Hans/site/">https://www.qgis.org/zh-Hans/site/</a><br>QGIS 下载页：<a href="https://www.qgis.org/zh-Hans/site/forusers/download.html">https://www.qgis.org/zh-Hans/site/forusers/download.html</a></p></blockquote></li></ul><h3 id="动力学标定"><a href="#动力学标定" class="headerlink" title="动力学标定"></a>动力学标定</h3><hr><h4 id="动力学标定概述"><a href="#动力学标定概述" class="headerlink" title="动力学标定概述"></a>动力学标定概述</h4><ul><li><p>动力学标定是通过采集车辆底盘在运行时油门幅度、刹车幅度、车辆速度、车辆加速度等数据，建立车辆动力学模型的过程。动力学标定的结果是一张车辆踏板标定表，反映了油门和刹车作用在车辆上的效果。Apollo D-Kit的动力学标定过程可以在Dreamview中可视化完成。</p></li><li><p>Apollo D-Kit的动力学标定需要采集低速小油门、低速大油门、低速急刹车、低速缓刹车、高速大油门、高速小油门、高速急刹车、高速缓刹车这8种场景条件下的运行数据，其中速度条件、油门条件和刹车条件的定义如下：</p><ul><li><p><strong>速度条件</strong>：低速——<script type="math/tex">0\sim 2.5m/s</script>；高速——<script type="math/tex">\geq 2.5m/s</script>。</p></li><li><p><strong>油门条件</strong>：小油门——<script type="math/tex">deadzone\sim 24%</script>；大油门——<script type="math/tex">\geq 24%</script>。</p></li><li><p><strong>刹车条件</strong>：缓刹车——<script type="math/tex">deadzone\sim 28%</script>；急刹车——<script type="math/tex">\geq 28%</script>。</p></li></ul></li><li><p>上述标定配置位于<code>apollo/modules/calibration/data/dev_kit/dreamview_conf/data_collection_table.pb.txt</code>中。</p></li></ul><h4 id="动力学标定流程"><a href="#动力学标定流程" class="headerlink" title="动力学标定流程"></a>动力学标定流程</h4><h5 id="数据采集"><a href="#数据采集" class="headerlink" title="数据采集"></a>数据采集</h5><ul><li><p>将Apollo D-Kit移动至足够长的直线路段后，启动Apollo D-Kit，进入Docker容器内，并通过<code>bootstrap.sh</code>脚本启动Dreamview。在<code>--setup mode--</code>中选择<code>vehicle calibration</code>并将<code>--vehicle--</code>置为<code>Dev_Kit</code>。</p></li><li><p>在下方<code>Others</code>区域中勾选<code>Data Collection Moniter</code>，在右侧弹出的面板中点击<code>Go Straight</code>按钮，下方出现8个进度条，分别对应上述8种场景条件。在后续的驾驶过程中，当满足其中的一种场景条件时，相应的进度条就会增加，当所有进度条都满了之后，即可完成数据采集。</p></li><li><p>在Docker内终端运行命令<code>cyber_monitor</code>，检查<code>/apollo/canbus/chassis</code>是否有数据，检查<code>/apollo/sensor/gnss/best_pose</code>是否有数据且<code>sol_type</code>字段是否为<code>NARROW_INT</code>，检查<code>/apollo/localization/pose</code>是否有数据。若均无误，在<code>Dreamview</code>中点击左侧<code>Module Controller</code>，打开三个开关，开始操作车辆采集数据。</p></li><li><p>当采集完成后，在<code>Module Controller</code>中关闭<code>Recoder</code>开关。在<code>apollo/data/bag</code>下可以找到一个形如<code>yyyy-MM-dd-HH-mm-ss</code>和一个形如<code>yyyy-MM-dd-HH-mm-ss_s</code>的两个文件夹，复制出其中不带<code>_s</code>后缀的文件夹备用。</p></li><li><p>（Optional）如果采集过程中出现失败，重新进入Dreamview无法打开<code>Go Straight</code>页面，需要运行<code>rm -rf ~/apollo/data/bag/*</code>删除残缺的数据文件，在Docker内执行<code>bash apollo.sh build_opt</code>重新编译工程。</p></li></ul><h5 id="标定任务提交"><a href="#标定任务提交" class="headerlink" title="标定任务提交"></a>标定任务提交</h5><ul><li><p>登录百度智能云，打开BOS服务，在Bucket根目录下新建一个任务文件夹，例如<code>Task001</code>，在其中建立一个代表车辆的文件夹，例如<code>Dev_Kit</code>，在其中建立一个名为<code>Records</code>的文件夹，在、再上传一个该车辆的配置文件（位于<code>/apollo/modules/calibration/data/dev_kit/vehicle_param.pb.txt</code>），再<code>Records</code>文件夹下建立一个形如<code>yyyy-MM-dd-HH-mm-ss</code>的文件夹，将Apollo采集的数据传到该文件夹下。需要注意的是，BOS服务按量计费，再进行后续操作之前需要在百度智能云中预存足够的费用。</p></li><li><p>打开<a href="http://bce.apollo.auto">http://bce.apollo.auto</a>，在左侧选择<code>Apollo Fuel</code>并在二级菜单中选择<code>任务</code>，点击“新建任务”，在下拉菜单中选择“控制评测”，在“输入数据路径”中填写上一个步骤中建立的任务文件夹名，即<code>Task001</code>，点击“提交任务”。</p></li></ul><h5 id="更新配置文件"><a href="#更新配置文件" class="headerlink" title="更新配置文件"></a>更新配置文件</h5><ul><li>云标定完成后，会将标定结果发送至预留的邮箱中，压缩包是<code>.tar.gz</code>格式，解压后将标定结果用于替换<code>apollo/modules/calibration/data/dev_kit/control_conf.pb.txt</code>中的<code>lon_controller_conf</code>字段下的<code>calibration_table</code>字段。</li></ul><h3 id="循迹实验"><a href="#循迹实验" class="headerlink" title="循迹实验"></a>循迹实验</h3><hr><h4 id="录制阶段"><a href="#录制阶段" class="headerlink" title="录制阶段"></a>录制阶段</h4><ul><li><p>在完成车辆的动力学标定之后，可以进行车辆的循迹实验。启动工控机，在命令行下打开CAN卡，启动Docker容器，进入Docker内环境，使用<code>bash apollo.sh build_opt_gpu</code>命令重新编译工程，并通过<code>bash scripts/bootstrap.sh</code>命令启动Dreamview。</p></li><li><p>在<code>--setup mode--</code>中选择模式<code>Rtk</code>，并在<code>--vehicle--</code>中选择<code>Dev Kit</code>车型，在侧边栏中进入<code>Module Controller</code>页面，打开<code>Canbus</code>、<code>GPS</code>和<code>Localization</code>三个模块，在<code>cyber_monitor</code>中监听<code>/apollo/canbus/chassis</code>、<code>/apollo/canbus/chassis_detail</code>、<code>/apollo/sensor/gnss/best_pose</code>、<code>/apollo/localization/pose</code>四个Channel的数据是否正常。</p></li><li><p>如各个Channel的数据均符合要求，可以将车辆开至合适的场地，记录下车辆的车头方向和起点位置，点击<code>RTK Recorder</code>启动循迹数据的记录模块录制数据，此时使用遥控器手动控制车辆前进一段轨迹，在达到终点后，再次点击<code>RTK Recorder</code>，关闭录制。需要注意的是，车辆停止和关闭数据录制之间的间隔需要尽可能的短，以免录制过多冗余数据。</p></li></ul><h4 id="回放阶段"><a href="#回放阶段" class="headerlink" title="回放阶段"></a>回放阶段</h4><ul><li><p>驾驶车辆返回录制过程的起始点后，将遥控器放权，在<code>Module Controller</code>页面中打开<code>Control</code>模块，再启动<code>RTK Player</code>模块，此时在界面中应规划出一条光滑无毛刺的蓝色轨迹线，该轨迹即是录制阶段车辆行驶的轨迹，请确认轨迹是否符合预期。</p></li><li><p>在侧边栏点击<code>Task</code>，在下方的控制区域点击<code>Start Auto</code>，此时车辆将按照规划的轨迹执行自动驾驶，此时可以观察界面中不断replan的轨迹和车辆的实时驾驶状态是否科学安全，如有异常，随时使用遥控器接管车辆。</p></li><li><p>到达终点后，车辆会自动停止，此时先使用遥控器接管车辆，再在<code>Module Controller</code>页面中关闭<code>RTK Player</code>和<code>Control</code>模块，完成循迹实验。</p></li></ul><h4 id="循迹实验的调试"><a href="#循迹实验的调试" class="headerlink" title="循迹实验的调试"></a>循迹实验的调试</h4><h5 id="CAN总线的调试"><a href="#CAN总线的调试" class="headerlink" title="CAN总线的调试"></a>CAN总线的调试</h5><ul><li><p>Dreamview中高层下达的指令通过CAN总线控制地盘的运动，如果车辆的循迹运动有问题，可以检查CAN总线的控制是否正常。在Apollo的工程代码中，官方提供的<code>canbus_teleop</code>脚本能实现这一功能，在Docker的内环境中执行下列命令可以进入一个这个脚本的CLI页面。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /apollo/scripts</span><br><span class="line">bash canbus_teleop.sh</span><br></pre></td></tr></table></figure></li><li><p>在CLI中会显示该工具的使用方法，一般说来，需要先同时按下<code>m</code>键和<code>0</code>键重置系统，在同时按下<code>m</code>键和<code>1</code>键开始对底盘进行控制，连续按下<code>a</code>键和<code>d</code>键观察车前轮是否有左右运动，同时按下<code>g</code>键和<code>1</code>键为汽车挂前进挡，连续按下<code>w</code>键观察汽车是否前进，连续按下<code>s</code>键观察汽车是否能停下来。</p></li><li><p>如果上述操作均无异常，说明CAN总线通信没有问题。</p></li></ul><h5 id="录制数据的可视化"><a href="#录制数据的可视化" class="headerlink" title="录制数据的可视化"></a>录制数据的可视化</h5><ul><li><p>在录制阶段，RTK Recorder采集到的数据会被保存在<code>apollo/data/log/garage.csv</code>这一文件中，其中包括车辆在每一时刻下的位置信息、速度、加速度、油门档位等各种驾驶信息，记录的频率是100Hz。</p></li><li><p>对于其常规数据的可视化，通过Excel中的图表工具就可以完成，对于GPS信息，文件中记录的是WGS84坐标系下UTM投影后的值，这个信息可以通过QGIS软件进行可视化，具体的操作步骤可以参考下方其官方文档中的说明，更多的关于GIS的内容可以在下方的网站中获得：</p><blockquote><p>Importing a delimited text file：<a href="https://docs.qgis.org/3.10/en/docs/user_manual/managing_data_source/opening_data.html?highlight=csv#importing-a-delimited-text-file">https://docs.qgis.org/3.10/en/docs/user_manual/managing_data_source/opening_data.html?highlight=csv#importing-a-delimited-text-file</a><br>麻辣GIS：<a href="https://malagis.com/">https://malagis.com/</a></p></blockquote></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;准备工作&quot;&gt;&lt;a href=&quot;#准备工作&quot; class=&quot;headerlink&quot; title=&quot;准备工作&quot;&gt;&lt;/a&gt;准备工作&lt;/h3&gt;&lt;hr&gt;
&lt;h4 id=&quot;Apollo-Fuel服务的申请&quot;&gt;&lt;a href=&quot;#Apollo-Fuel服务的申请&quot; class=</summary>
      
    
    
    
    <category term="开发和调试笔记" scheme="http://bye-lemon.github.io/categories/%E5%BC%80%E5%8F%91%E5%92%8C%E8%B0%83%E8%AF%95%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Apollo" scheme="http://bye-lemon.github.io/tags/Apollo/"/>
    
  </entry>
  
  <entry>
    <title>Apollo D-Kit 调试笔记（一）：系统安装与传感器集成</title>
    <link href="http://bye-lemon.github.io/post/11e/"/>
    <id>http://bye-lemon.github.io/post/11e/</id>
    <published>2020-10-15T07:37:36.000Z</published>
    <updated>2021-01-17T05:45:09.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h3><hr><h4 id="Apollo-D-Kit相关网站"><a href="#Apollo-D-Kit相关网站" class="headerlink" title="Apollo D-Kit相关网站"></a>Apollo D-Kit相关网站</h4><blockquote><p>Apollo Project 官网：<a href="https://apollo.auto/">https://apollo.auto/</a><br>Apollo Github Repo：<a href="https://github.com/ApolloAuto/apollo">https://github.com/ApolloAuto/apollo</a><br>Apollo D-Kit 用户手册：<a href="https://github.com/ApolloAuto/apollo/blob/r5.5.0/docs/specs/D-kit/Vehicle_Guide/Quick_Start_V04.md">https://github.com/ApolloAuto/apollo/blob/r5.5.0/docs/specs/D-kit/Vehicle_Guide/Quick_Start_V04.md</a><br>Apollo D-Kit 官方文档：<a href="https://github.com/ApolloAuto/apollo/tree/r5.5.0/docs/specs/D-kit">https://github.com/ApolloAuto/apollo/tree/r5.5.0/docs/specs/D-kit</a><br>Apollo 仿真、反馈和服务中心：<a href="http://bce.apollo.auto/accounts?locale=zh-cn">http://bce.apollo.auto/accounts?locale=zh-cn</a></p></blockquote><h4 id="设置工控机满功率运行"><a href="#设置工控机满功率运行" class="headerlink" title="设置工控机满功率运行"></a>设置工控机满功率运行</h4><ul><li>在工控机启动的过程中，按<code>F2</code>键进入BIOS菜单，在<code>Power</code>选项卡下将<code>SKU POWER CONFIG</code>设置为<code>MAX TDP</code>，使工控机始终保持以最佳性能状态运行。</li></ul><h4 id="安装Ubuntu操作系统"><a href="#安装Ubuntu操作系统" class="headerlink" title="安装Ubuntu操作系统"></a>安装Ubuntu操作系统</h4><ul><li><p>Apollo平台的运行需要依赖Linux操作系统，百度官方推荐的版本是Ubuntu 18.04.3，目前Ubuntu 18.04LTS的最新版本为Ubuntu 18.04.5，实测表明，在该版本上Apollo系统可用。系统的ISO镜像可以在Ubuntu官方获得。</p><blockquote><p>Ubuntu官方网站：<a href="https://ubuntu.com/">https://ubuntu.com/</a></p><p>Ubuntu 18.04.5 BitTorrent：<a href="https://releases.ubuntu.com/18.04/ubuntu-18.04.5-desktop-amd64.iso.torrent">https://releases.ubuntu.com/18.04/ubuntu-18.04.5-desktop-amd64.iso.torrent</a></p></blockquote></li><li><p>下载好Ubuntu镜像之后，即可制作引导盘，Rufus是一款不错的引导盘制作工具。插入U盘，在Rufus中使用默认设置制作引导盘后，在工控机的BIOS之中选择<code>Legacy</code>方式引导，将第一启动设备设置为所制作的U盘引导盘即可从该引导盘启动，按照提示，即可完成系统的安装。</p><blockquote><p>Rufus下载地址：<a href="http://rufus.ie/">http://rufus.ie/</a></p><p>Ubuntu安装指南：<a href="https://ubuntu.com/tutorials/install-ubuntu-desktop">https://ubuntu.com/tutorials/install-ubuntu-desktop</a></p></blockquote></li><li><p>（可选）如果在使用<code>apt</code>包管理工具安装软件时，Ubuntu默认的官方源下载速度不够理想，可以更换系统自带的软件源，可以使用可视化操作，也可以使用Super权限对<code>/etc/apt/sources.list</code>进行修改来完成。</p><ul><li><p>使用可视化操作，可以打开左侧快捷启动栏里的<code>Software</code>软件，单机左上方软件名称，在下拉菜单里选择第一项，进入狗，在Server一栏，Choose Best Server。返回时，通过Reload刷新本地信息。</p></li><li><p>如果通过修改配置文件的方式更换软件园，可以参照清华开源软件镜像站<a href="https://mirrors.tuna.tsinghua.edu.cn/">TUNA</a>给出的帮助信息，完成替换，具体的操作方式参见<a href="https://mirrors.tuna.tsinghua.edu.cn/help/ubuntu/">https://mirrors.tuna.tsinghua.edu.cn/help/ubuntu/</a>，完成替换之后，使用<code>sudo apt update</code>完成本地缓存的更新。</p></li></ul></li></ul><h3 id="编译安装Apollo内核"><a href="#编译安装Apollo内核" class="headerlink" title="编译安装Apollo内核"></a>编译安装Apollo内核</h3><hr><ul><li><p>在进行各类驱动包的安装之前，需要先安装一些必要的工具，这是工具将被用来完成后续的编译工作，具体的安装可以通过以下命令完成</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install vim git wget curl make</span><br></pre></td></tr></table></figure></li><li><p>Apollo内核的编译要求使用4.8版本编译工具包，可以使用<code>gcc -- version</code>和<code>g++ --version</code>命令检查对应工具的版本，如不满足4.8版本的要求，也使用下述命令安装特定版本。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install g++-4.8 g++-4.8-multilib gcc-4.8 gcc-4.8-multilib</span><br><span class="line">sudo /usr/bin/update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-4.8 99 --slave /usr/bin/g++ g++ /usr/bin/g++-4.8</span><br></pre></td></tr></table></figure></li><li><p>完成编译工具的准备之后，即可开始编译Apollo Kernel，Apollo Kernel是一个实时操作系统内核，Apollo D-Kit的正常使用需要Apollo Kernel提供的系统及支持。编译Apollo Kernel的第一步是获取其源码，Apollo Kernel最新一次的Release版本，可以从<a href="https://github.com/ApolloAuto/apollo-kernel/releases/tag/1.5.5">https://github.com/ApolloAuto/apollo-kernel/releases/tag/1.5.5</a>处获得。</p></li><li><p>切换到保存有源码包的目录，依次执行一下三条语句，即可完成对源码的解压、编译与安装。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf linux-4.4.32-apollo-1.5.5.tar.gz</span><br><span class="line"><span class="built_in">cd</span> install</span><br><span class="line">sudo bash install_kernel.sh</span><br></pre></td></tr></table></figure></li><li><p>Ubuntu使用Grub进行系统的引导启动，在完成Apollo Kernel的编译安装之后，需要对<code>grub</code>的部分而皮质进行修改，以便在后续的使用中选择从Apollo Kernel引导。Grub的配置文件是<code>/etc/default/grub</code>，在Super权限下编辑该文件，将<code>grub_timeout_style=hidden</code>注释掉，修改<code>grub_timeout</code>的值为<code>10</code>，将<code>grub_cmdline_linux_default</code>的值由<code>quiet splash</code>修改为<code>text</code>。完成修改并保存后，使用<code>sudo update-grub</code>命令是修改的配置生效，重新启动工控机。</p></li><li><p>在重启工控机进入到Grub界面时，选择<code>Ubuntu Advantace Settings</code>，在其中选择Apollo Kernel的引导项，重启后，使用<code>Crtl+Alt+T</code>打开终端，输入命令<code>uname -r</code>并检查输出，若包含<code>4.4.32-apollo-2-RT</code>说明安装成功。</p></li></ul><h3 id="编译安装硬件驱动包"><a href="#编译安装硬件驱动包" class="headerlink" title="编译安装硬件驱动包"></a>编译安装硬件驱动包</h3><hr><h4 id="编译安装网卡驱动"><a href="#编译安装网卡驱动" class="headerlink" title="编译安装网卡驱动"></a>编译安装网卡驱动</h4><ul><li><p>D-Kit的工控机背板上有两个有两个以太网接口，默认情况下，其中一个没有驱动，无法进行连接，需要为其额外编译安装一份驱动程序。驱动程序源码可以在英特尔网站上获取，具体的下载页面是<a href="https://downloadcenter.intel.com/zh-cn/download/15817?_ga=1.159975677.114505945.1484457019">https://downloadcenter.intel.com/zh-cn/download/15817?_ga=1.159975677.114505945.1484457019</a>，目前，该驱动的最新版本为3.8.4版本。</p></li><li><p>下载好驱动源码后，可以依次执行下列命令完成有线网卡驱动的安装流程。在完成安装后，检验两个以太网接口，均可识别到有线连接，即可执行后续操作。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf e1000e-3.8.4.tar.gz</span><br><span class="line"><span class="built_in">cd</span> e1000e-3.8.4/src/</span><br><span class="line">sudo make install</span><br><span class="line">sudo modprobe e1000e</span><br></pre></td></tr></table></figure></li><li><p>（可选）为了更方便的实现网络连接，可以为工控机编译安装无线网卡的驱动，以便在维护工控机时更方便的使用Wi-Fi连接。在无线网卡的选择上，一种方便可行的方案是选购Tenda U6无线网卡。下面以Tenda U6无线网卡为例，介绍无线网卡的驱动编译。</p><ul><li><p>类似地，首先在Tenda官方网站上获取无线网卡驱动的源码，Tenda U6网卡的驱动源码可以在<a href="https://www.tenda.com.cn/download/detail-2656.html">https://www.tenda.com.cn/download/detail-2656.html</a>页面下载。</p></li><li><p>切换到源码包所在的目录，使用<code>unzip</code>命令解压，打开其中名为<code>RTL8192EU_linux_v5.6.4_35685_COEX20171113-0047.20191108</code>的目录，执行命令<code>sudo bash install.sh</code>即可完成驱动的编译和安装。</p></li><li><p>验证工控机是否能够搜索并连接到无线网络，如果可以，说明安装成功。</p></li></ul></li></ul><h4 id="编译安装GPU驱动"><a href="#编译安装GPU驱动" class="headerlink" title="编译安装GPU驱动"></a>编译安装GPU驱动</h4><ul><li><p>为了让Apollo平台可以在拥有GPU支持的情况下高效运行，需要为工控机编译安装GPU驱动。需要注意的是，GPU驱动的编译安装不支持在实时系统上进行，所以需要将工控机以普通方式引导启动，即在Grub界面中不选择高级选项直接引导系统。</p></li><li><p>Apollo Kernel的官方Github仓库提供了一个用于安装GPU驱动的脚本，可以使用<code>wget https://github.com/ApolloAuto/apollo-kernel/blob/master/linux/install-nvidia.sh</code>将该自动化脚本下载到本地。随后，通过<code>sudo bash install-nvidia.sh</code>完成驱动安装。</p></li><li><p>在完成显卡内核驱动的安装后，该脚本还会生成一个名为<code>NVIDIA-Linux-x86_64-430.50.run</code>的文件，使用以下命令完成用户驱动库的安装。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo bash ./NVIDIA-Linux-x86_64-430.50.run --no-x-check -a -s --no-kernel-module  </span><br></pre></td></tr></table></figure></li><li><p>完成安装之后，可以使用<code>cat /proc/driver/nvidia/version</code>命令检查驱动内核，若出现“430.50”字样，说明安装成功，随后可以使用<code>nvidia-smi</code>命令查看显卡信息，若能正常输出，说明用户库也正常安装，可供后续操作。</p></li></ul><h4 id="编译安装CAN驱动"><a href="#编译安装CAN驱动" class="headerlink" title="编译安装CAN驱动"></a>编译安装CAN驱动</h4><ul><li><p>工控机与底盘等硬件设备的通信采用的是CAN通信，为此，需要为工控机安装CAN驱动。在安装驱动之前，需要先添加一条重命名规则，将CAN设备重命名为<code>ttyACM10</code>。通过命令<code>ll /sys/class/tty/ttyACM*</code>可以查看存在的ACM设备，记录下终端显示的形如<code>1-10:1.0</code>的一组编号，使用<code>sudo vim /etc/udev/rules.d/99-kernel-rename-emuc.rules</code>命令进入编辑器，按下<code>i</code>进入编辑模式，输入<code>ACTION==&quot;add&quot;,SUBSYSTEM==&quot;tty&quot;,MODE==&quot;0777&quot;,KERNELS==&quot;1-10:1.0&quot;,SYMLINK+=&quot;ttyACM10</code>，注意，这里的<code>1-10:1.0</code>应替换为前述过程中终端显示的编号，完成输入之后，按下<code>ESC</code>推出编辑模式，在输入<code>:wq</code>即可保存修改。</p></li><li><p>重启工控机，使用命令<code>ll /dev/ttyACM*</code>检查<code>ttyACM10</code>是否存在，如存在，可执行后续的驱动安装过程。</p></li><li><p>打开链接<a href="https://www.innodisk.com/Download_file?D7856A02AF20333811EBF83A6E6FDFE31262BBEB35FDA8E63B4FCD36B5C237175D714D7286AF87B5">https://www.innodisk.com/Download_file?D7856A02AF20333811EBF83A6E6FDFE31262BBEB35FDA8E63B4FCD36B5C237175D714D7286AF87B5</a>下载EMUC-B202的驱动包，使用下列命令解压并将驱动目录拷贝到用户目录下。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">unzip EMUC-B202.zip</span><br><span class="line"><span class="built_in">cd</span> EMUC-B202/Linux</span><br><span class="line">unzip EMUC-B202_SocketCAN_Driver_v2.3_Utility_v2.2.zip</span><br><span class="line">mv EMUC-B202_SocketCAN_Driver_v2.3_Utility_v2.2/ ~/SocketCan/</span><br></pre></td></tr></table></figure></li><li><p>此时，即可对CAN驱动进行编译。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/SocketCan</span><br><span class="line">sudo make</span><br></pre></td></tr></table></figure></li><li><p>完成编译之后，使用<code>gedit start.sh</code>命令将文件中<code>sudo ./emucd_64 -s9 ttyACM0 can0 can1</code>一行修改为<code>sudo ./emucd_64 -s7 ttyACM10 can0 can1</code>，执行<code>sudo bash start.sh</code>验证是否能启动CAN通信。运行启动脚本后终端可能会显示<code>rmmod: ERROR: Module emuc2socketcan is not currently loaded</code>，不必担心，这是正常输出，此时，CAN卡已启动成功。</p></li><li><p>在后续Apollo D-kit的正常使用中，每次使用之前，均需要在Docker外执行该启动脚本，打开CAN通信。</p></li></ul><h3 id="编译安装Apollo软件包"><a href="#编译安装Apollo软件包" class="headerlink" title="编译安装Apollo软件包"></a>编译安装Apollo软件包</h3><hr><h4 id="准备Docker环境"><a href="#准备Docker环境" class="headerlink" title="准备Docker环境"></a>准备Docker环境</h4><ul><li><p>Apollo软件包使用Docker容器进行封装，因此，需要为工控机安装Docker环境，使用<code>wget https://github.com/ApolloAuto/apollo/blob/r5.5.0/docker/setup_host/install_nvidia_docker.sh</code>下载自动化脚本，完成下载后，执行<code>sudo bash install_nvidia_docker.sh</code>完成自动化安装。</p></li><li><p>为检验Docker安装是否成功，可以执行<code>sudo docker run hello-world</code>，如果Docker安装成功，可以看到有helloworld输出。</p></li></ul><h4 id="准备Apollo源代码"><a href="#准备Apollo源代码" class="headerlink" title="准备Apollo源代码"></a>准备Apollo源代码</h4><ul><li><p>在Docker环境正常搭建之后，即可从Apollo的官方仓库中克隆Apollo最新的源码包，需要注意的是，Apollo D-Kit套件的很多代码提交比较新，Release页面上的5.5.0发行版尚不足以支持D-Kit的使用，因此需要克隆Apollo的主仓库，以获取5.5.0分支上最新的代码提交。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~</span><br><span class="line">git <span class="built_in">clone</span> https://github.com/ApolloAuto/apollo.git</span><br><span class="line"><span class="built_in">cd</span> apollo</span><br><span class="line">git checkout r5.5.0</span><br></pre></td></tr></table></figure></li><li><p>完成之后，使用<code>git branch</code>命令检查是否处于5.5.0分支上。上述命令在执行过程中约需要从Github上下载2.2G的文件，执行时间受网络环境决定。若在克隆过程中出现TLS连接错误，可能是GNUTLS的问题，需要手动编译基于OpenSSL的Git工具，其过程如下：</p><ul><li><p>首先，需要准备必要的Git的最小依赖，使用命令<code>sudo apt install dh-autoreconf libcurl4-openssl-dev  libexpat1-dev fettext libz-dev libssl-dev install-info</code>安装这些必要依赖。</p></li><li><p>Git最新的发行版可以从<a href="https://github.com/git/git/releases">https://github.com/git/git/releases</a>处获得，以2.28.0版本为例，下载<code>.tar.gz</code>格式的源码包后，在对应路径下打开终端，使用以下命令编译安装。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf git-2.28.0.tar.gz</span><br><span class="line"><span class="built_in">cd</span> git-2.28.0</span><br><span class="line">make configure</span><br><span class="line">./configure --prefix=/usr</span><br><span class="line">make</span><br><span class="line">sudo make install</span><br></pre></td></tr></table></figure></li></ul></li><li><p>另外，Github原生使用亚马逊的CDN，访问起来不是很友好，Repo的克隆和Release的下载一般较为缓慢，Repo的克隆可以通过导入Gitee来实现加速，Release包的下载可以通过以下两个网站来提高下载速度：</p><blockquote><p>Widora：<a href="https://d.serctl.com/">https://d.serctl.com/</a></p><p>MangoGeek：<a href="http://gitd.cc/">http://gitd.cc/</a></p></blockquote></li></ul><h4 id="编译Apollo源代码"><a href="#编译Apollo源代码" class="headerlink" title="编译Apollo源代码"></a>编译Apollo源代码</h4><ul><li><p>准备好源码之后，需要将源代码所在目录加入环境变量，重新引入设置，使其生效。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;export APOLLO_HOME=<span class="subst">$(pwd)</span>&quot;</span> &gt;&gt; ~/.bashrc</span><br><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure></li><li><p>添加了环境变量之后，还需要将当前用户加入Docker用户组，并授权必要权限，完成之后，重启工控机。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo gpasswd -a <span class="variable">$USER</span> docker  </span><br><span class="line">sudo usermod -aG docker <span class="variable">$USER</span>  </span><br><span class="line">sudo chmod 777 /var/run/docker.sock</span><br></pre></td></tr></table></figure></li><li><p>系统重启之后，打开终端，使用<code>cd ~/apollo</code>切换工作路径到Apollo源码文件夹下，运行<code>bash docker/scripts/dev_start.sh</code>，将自动完成Apollo的Image镜像的下载和构建，该过程的执行时间受网络质量影响。</p></li><li><p>完成构建之后，使用<code>bash docker/scripts/dev_into.sh</code>可以进入Docker容器内的终端，运行<code>bash apollo.sh build_opt</code>完成Apollo软件包的编译，该过程约需20分钟。</p></li><li><p>编译完成之后，使用<code>bash scripts/bootstrap.sh</code>可以启动Apollo的浏览器控制端Dreamview，在浏览器中访问<a href="http://localhost:8888">http://localhost:8888</a>，如果正常显示Dreamview控制页面，说明没有问题。</p></li><li><p>在后续的正常使用中，每次启动工控机均需要进入Apollo工作目录，使用<code>bash docker/scripts/dev_start.sh -n</code>启动容器，<code>-n</code>参数的添加会跳过对远端的版本更新检查，加快启动速度，随后执行<code>bash docker/scripts/dev_into.sh</code>并在Docker内终端执行<code>bash scripts/bootstrap.sh</code>。如果想要停止Dreamview服务，可以运行<code>bash scripts/bootstrap.sh stop</code>，在Docker内终端执行<code>exit</code>可以回到系统终端。</p></li></ul><h3 id="传感器集成与配置"><a href="#传感器集成与配置" class="headerlink" title="传感器集成与配置"></a>传感器集成与配置</h3><hr><h4 id="准备工作-1"><a href="#准备工作-1" class="headerlink" title="准备工作"></a>准备工作</h4><ul><li><p>在传感器的集成与配置工作开始之前，应参考一下文档完成硬件上的连接：</p><blockquote><p>Apollo D-Kit传感器集成说明：<a href="https://github.com/ApolloAuto/apollo/blob/r5.5.0/docs/specs/D-kit/Vehicle_Guide/Apollo_D-kit_sensor_integration_V04.md">https://github.com/ApolloAuto/apollo/blob/r5.5.0/docs/specs/D-kit/Vehicle_Guide/Apollo_D-kit_sensor_integration_V04.md</a></p></blockquote></li><li><p>Apollo平台使用一组差分GPS实现厘米级高精度定位，其所使用的定位技术是实时动态载波相位差分技术（Real-time Kinematic，RTK）。RTK作业需要有对应的服务支持，千寻位置提供的FindCM服务是可供选择的一种方案。</p><blockquote><p>千寻知寸服务：<a href="https://mall.qxwz.com/market/services/FindCM">https://mall.qxwz.com/market/services/FindCM</a></p></blockquote></li><li><p>Apollo有两个以太网，二者分别与4G路由器和激光雷达相连，为了方便对两个设备的有序访问，可以为两个以太网连接设定静态IP，在桌面右上角点击网络图标，选择有线连接下方的Setting，将与4G路由器相连的接口IP、子网掩码和网关设成<code>192.168.0.118</code>、<code>255.255.255.0</code>、<code>192.168.0.1</code>；将与激光雷达相连的接口IP、子网掩码和网关设成<code>192.168.1.118</code>、<code>255.255.255.0</code>、<code>192.168.1.1</code>，关闭后重新打开连接，使其生效。</p></li></ul><h4 id="Newton-M2控制器的配置"><a href="#Newton-M2控制器的配置" class="headerlink" title="Newton M2控制器的配置"></a>Newton M2控制器的配置</h4><ul><li><p>使用<code>ll /sys/class/tty/ttyACM0</code>命令检查M2主机是否已经与工控机正常连接，如果连接正常，可以看到一串形如<code>1-10:1.0</code>的编号，通过<code>sudo vim /etc/udev/rules.d/99-kernel-rename-imu.rules</code>创建并编辑配置文件，在文件中键入<code>ACTION==&quot;add&quot;,SUBSYSTEM==&quot;tty&quot;,MODE==&quot;0777&quot;,KERNELS==&quot;1-10:1.0&quot;,SYMLINK+=&quot;imu&quot;</code>，其中，<code>KERNELS</code>字段替换为ttyACM0对应的编号，保存配置文件，重启工控机。</p></li><li><p>使用<code>ll /dev/imu</code>查看是否存在设备，如存在，说明配置无误，可以进行M2的配置。M2的配置需要通过串口进行，为了方便配置，可以创建一个配置文件<code>imu.conf</code>在其中写入以下内容，并将<code>$cmd,set,netuser,[FindCM UserName]:[FindCM Password]*ff</code>修改为FindCM提供的账号和密码。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$cmd</span>,<span class="built_in">set</span>,leverarm,gnss,0,-0.1,0.6*ff</span><br><span class="line"><span class="variable">$cmd</span>,<span class="built_in">set</span>,headoffset,0*ff</span><br><span class="line"><span class="variable">$cmd</span>,<span class="built_in">set</span>,navmode,FineAlign,off*ff</span><br><span class="line"><span class="variable">$cmd</span>,<span class="built_in">set</span>,navmode,coarsealign,off*ff</span><br><span class="line"><span class="variable">$cmd</span>,<span class="built_in">set</span>,navmode,dynamicalign,on*ff</span><br><span class="line"><span class="variable">$cmd</span>,<span class="built_in">set</span>,navmode,gnss,double*ff</span><br><span class="line"><span class="variable">$cmd</span>,<span class="built_in">set</span>,navmode,carmode,on*ff</span><br><span class="line"><span class="variable">$cmd</span>,<span class="built_in">set</span>,navmode,zupt,on*ff</span><br><span class="line"><span class="variable">$cmd</span>,<span class="built_in">set</span>,navmode,firmwareindex,0*ff</span><br><span class="line"><span class="variable">$cmd</span>,output,usb0,rawimub,0.010*ff</span><br><span class="line"><span class="variable">$cmd</span>,output,usb0,inspvab,0.010*ff</span><br><span class="line"><span class="variable">$cmd</span>,through,usb0,bestposb,1.000*ff</span><br><span class="line"><span class="variable">$cmd</span>,through,usb0,rangeb,1.000*ff</span><br><span class="line"><span class="variable">$cmd</span>,through,usb0,gpsephemb,1.000*ff</span><br><span class="line"><span class="variable">$cmd</span>,through,usb0,gloephemerisb,1.000*ff</span><br><span class="line"><span class="variable">$cmd</span>,through,usb0,bdsephemerisb,1.000*ff</span><br><span class="line"><span class="variable">$cmd</span>,through,usb0,headingb,1.000*ff</span><br><span class="line"><span class="variable">$cmd</span>,<span class="built_in">set</span>,localip,192,168,0,196*ff</span><br><span class="line"><span class="variable">$cmd</span>,<span class="built_in">set</span>,localmask,255,255,255,0*ff</span><br><span class="line"><span class="variable">$cmd</span>,<span class="built_in">set</span>,localgate,192,168,0,1*ff</span><br><span class="line"><span class="variable">$cmd</span>,<span class="built_in">set</span>,netipport,203,107,45,154,8002*ff</span><br><span class="line"><span class="variable">$cmd</span>,<span class="built_in">set</span>,netuser,[FindCM UserName]:[FindCM Password]*ff</span><br><span class="line"><span class="variable">$cmd</span>,<span class="built_in">set</span>,mountpoint,AUTO*ff</span><br><span class="line"><span class="variable">$cmd</span>,<span class="built_in">set</span>,ntrip,<span class="built_in">enable</span>,<span class="built_in">enable</span>*ff</span><br><span class="line">ppscontrol <span class="built_in">enable</span> positive 1.0 10000</span><br><span class="line"><span class="built_in">log</span> com3 gprmc ontime 1 0.25</span><br><span class="line"><span class="variable">$cmd</span>,save,config*ff</span><br></pre></td></tr></table></figure></li><li><p>使用命令<code>sudo apt install cutecom</code>安装串口调试助手，执行命令<code>sudo cutecom</code>打开程序，以<code>115200</code>的波特率打开<code>ttyS0</code>，点击下方的<code>Open</code>按钮，打开保存的配置文件，向M2主机发送配置。如配置成功，应收到25条<code>$cmd,config,ok*ff</code>的回复，然后为M2主机重新上电。</p></li><li><p>完成M2主机上的配置之后，工控机上Apollo项目的配置文件也应同步修改，具体应该修改的内容包括以下几个文件：</p><ul><li><p>GNSS配置：编辑配置文件<code>modules/calibration/data/dev_kit/gnss_conf/gnss_conf.pb.txt</code>，修改其中<code>proj4_text: &quot;+proj=utm +zone=50 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs&quot;</code>一行的<code>+zone</code>参数，将其改为所在地区的UTM Zone，50对应了北京，大连的UTM Zone为51，该值可以通过<script type="math/tex">utmzone=\lfloor \lfloor longitude \rfloor / 6 \rfloor + 31</script>计算。</p></li><li><p>Localization配置：编辑配置文件<code>modules/calibration/data/dev_kit/localization_conf/localization.conf</code>，修改其中的<code>local_utm_zone_id</code>为上一环节中所计算的区域UTM Zone的值，修改其中<code>--enable_lidar_localization</code>的值为<code>false</code>。</p></li></ul></li><li><p>为验证配置是否生效，须进入Docker环境，重新编译Apollo工程，并通过<code>bootstrap.sh</code>脚本启动Dreamview，在其中打开各个传感器后，在Docker终端输入<code>cyber_monitor</code>命令，使用方向键查看<code>/apollo/canbus/chassis</code>、<code>/apollo/sensor/gnss/best_pose</code>、<code>/apollo/sensor/gnss/imu</code>和<code>/apollo/localization/pose</code>等Channel下是否有数据被采集。其中，<code>apollo/sensor/gnss/best_pose</code>中<code>sol_type</code>字段的值须为<code>NARROW_INT</code>。</p></li></ul><h4 id="Lidar和Radar的配置"><a href="#Lidar和Radar的配置" class="headerlink" title="Lidar和Radar的配置"></a>Lidar和Radar的配置</h4><ul><li><p>激光雷达的默认IP地址是<code>192.168.1.201</code>，通过浏览器访问该IP地址可以打开激光雷达的配置界面，将<code>HOST IP Address</code>的值修改为<code>255.255.255.255</code>，将<code>DATA Port</code>修改为<code>2369</code>，将<code>Telemetry Port</code>修改为<code>8309</code>，之后点击<code>Set</code>键和<code>Save Configure</code>保存配置。</p></li><li><p>D-Kit只使用了毫米波雷达的前向毫米波，未使用后向毫米波，因此，需要在<code>modules/drivers/radar/conti_radar/dag/conti_radar.dag</code>中删除后向毫米波的配置，具体应删除内容如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">components &#123;</span><br><span class="line">    class_name : &quot;ContiRadarCanbusComponent&quot;</span><br><span class="line">    config &#123;</span><br><span class="line">        name: &quot;conti_radar_rear&quot;</span><br><span class="line">        config_file_path:  &quot;&#x2F;apollo&#x2F;modules&#x2F;drivers&#x2F;radar&#x2F;conti_radar&#x2F;conf&#x2F;radar_rear_conf.pb.txt&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>启动Dreamview，在<code>cyber_monitor</code>中监控<code>tf</code>、<code>tf_static</code>和<code>/apollo/localization/pose</code>至出现定位数据后，监控<code>/apollo/sensor/lidar16/PointCloud2</code>、<code>/apollo/sensor/lidar16/Scan</code>和<code>/apollo/sensor/lidar16/compensator/PointCloud2</code>三个Channel，观察激光雷达数据是否正常，再监控<code>/apollo/sensor/radar/front/</code>，观察毫米波雷达数据是否正常。</p></li></ul><h4 id="摄像头的配置"><a href="#摄像头的配置" class="headerlink" title="摄像头的配置"></a>摄像头的配置</h4><ul><li><p>使用<code>ll /sys/class/video4linux/video*</code>命令查看工控机上所挂载的摄像头设备，记录下形如<code>1-10:1.0</code>的编号，通过<code>sudo vim /etc/udev/rules.d/99-webcam.rules</code>创建并编辑配置文件，在文件中键入下列内容并保存，其中，<code>KERNELS</code>字段替换为对应相机的编号，重启工控机，使用<code>ls /dev/camera</code>命令检查摄像头设备是否存在。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SUBSYSTEM==<span class="string">&quot;video4linux&quot;</span>, SUBSYSTEMS==<span class="string">&quot;usb&quot;</span>, KERNELS==<span class="string">&quot;2-6:1.0&quot;</span>, MODE=<span class="string">&quot;0666&quot;</span>, SYMLINK+=<span class="string">&quot;camera/left_front&quot;</span>, OWNER=<span class="string">&quot;apollo&quot;</span>, GROUP=<span class="string">&quot;apollo&quot;</span></span><br><span class="line">SUBSYSTEM==<span class="string">&quot;video4linux&quot;</span>, SUBSYSTEMS==<span class="string">&quot;usb&quot;</span>, KERNELS==<span class="string">&quot;2-7:1.0&quot;</span>, MODE=<span class="string">&quot;0666&quot;</span>, SYMLINK+=<span class="string">&quot;camera/right_front&quot;</span>, OWNER=<span class="string">&quot;apollo&quot;</span>, GROUP=<span class="string">&quot;apollo&quot;</span></span><br><span class="line">SUBSYSTEM==<span class="string">&quot;video4linux&quot;</span>, SUBSYSTEMS==<span class="string">&quot;usb&quot;</span>, KERNELS==<span class="string">&quot;2-8:1.0&quot;</span>, MODE=<span class="string">&quot;0666&quot;</span>, SYMLINK+=<span class="string">&quot;camera/front_12mm&quot;</span>, OWNER=<span class="string">&quot;apollo&quot;</span>, GROUP=<span class="string">&quot;apollo&quot;</span></span><br></pre></td></tr></table></figure></li><li><p>编辑Apollo工程下的<code>apollo/modules/drivers/camera/dag/camera.dag</code>文件，取消<code>camera_left_front</code>、<code>camera_right_front</code>两段内容的注释，进入Docker环境，使用<code>bash apollo.sh build_cyber</code>命令编译工程，运行<code>cyber_visualizer</code>可视化工具，查看<code>/apollo/sensor/camera/left_front/image</code>、<code>/apollo/sensor/camera/right_front/image</code>和<code>/apollo/sensor/camera/front_12mm/image</code>上的信息是否正常。</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;准备工作&quot;&gt;&lt;a href=&quot;#准备工作&quot; class=&quot;headerlink&quot; title=&quot;准备工作&quot;&gt;&lt;/a&gt;准备工作&lt;/h3&gt;&lt;hr&gt;
&lt;h4 id=&quot;Apollo-D-Kit相关网站&quot;&gt;&lt;a href=&quot;#Apollo-D-Kit相关网站&quot; class=</summary>
      
    
    
    
    <category term="开发和调试笔记" scheme="http://bye-lemon.github.io/categories/%E5%BC%80%E5%8F%91%E5%92%8C%E8%B0%83%E8%AF%95%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Apollo" scheme="http://bye-lemon.github.io/tags/Apollo/"/>
    
  </entry>
  
  <entry>
    <title>Apollo D-Kit 调试笔记（零）：修车备忘录</title>
    <link href="http://bye-lemon.github.io/post/d923/"/>
    <id>http://bye-lemon.github.io/post/d923/</id>
    <published>2020-10-13T08:16:45.000Z</published>
    <updated>2021-01-17T05:45:09.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="车前轮的零点飘移问题"><a href="#车前轮的零点飘移问题" class="headerlink" title="车前轮的零点飘移问题"></a>车前轮的零点飘移问题</h3><hr><ul><li><p>Apollo前轮的零点如果发生变化，可以按照如下步骤进行矫正：</p><ol><li>将遥控器电锁打开，置于正常状态；</li></ol><ol><li><p>按住左下方<code>End</code>键，顺时针（车轮右旋）或逆时针（车轮左旋）旋转右下方轮盘至合适位置；</p></li><li><p>按下左下方<code>Push</code>键，同时松开<code>End</code>键和<code>Push</code>键，听到Apollo发出两声，修改完成。</p></li></ol></li><li><p>上述操作如下图所示：<br><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20201023181348.png" alt=""></p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;车前轮的零点飘移问题&quot;&gt;&lt;a href=&quot;#车前轮的零点飘移问题&quot; class=&quot;headerlink&quot; title=&quot;车前轮的零点飘移问题&quot;&gt;&lt;/a&gt;车前轮的零点飘移问题&lt;/h3&gt;&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Apollo前轮的零点如果发生变化，可以按照如下</summary>
      
    
    
    
    <category term="开发和调试笔记" scheme="http://bye-lemon.github.io/categories/%E5%BC%80%E5%8F%91%E5%92%8C%E8%B0%83%E8%AF%95%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Apollo" scheme="http://bye-lemon.github.io/tags/Apollo/"/>
    
  </entry>
  
  <entry>
    <title>《Query-guided End-to-End Person Search》论文笔记</title>
    <link href="http://bye-lemon.github.io/post/ffa2/"/>
    <id>http://bye-lemon.github.io/post/ffa2/</id>
    <published>2020-08-09T08:35:52.000Z</published>
    <updated>2021-01-17T05:45:09.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul><li><h2 id="Query-guided-Person-Search"><a href="#Query-guided-Person-Search" class="headerlink" title="Query-guided Person Search"></a>Query-guided Person Search</h2></li><li><p>QEEPS是一个基于OIM</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;h2 id=&quot;Query-guided-Per</summary>
      
    
    
    
    <category term="论文笔记" scheme="http://bye-lemon.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Re-ID" scheme="http://bye-lemon.github.io/tags/Re-ID/"/>
    
    <category term="CVPR" scheme="http://bye-lemon.github.io/tags/CVPR/"/>
    
    <category term="Person Search" scheme="http://bye-lemon.github.io/tags/Person-Search/"/>
    
  </entry>
  
  <entry>
    <title>《Joint Detection and Identification Feature Learning for Person Search》论文笔记</title>
    <link href="http://bye-lemon.github.io/post/c6f5/"/>
    <id>http://bye-lemon.github.io/post/c6f5/</id>
    <published>2020-08-09T06:28:52.000Z</published>
    <updated>2021-01-17T05:45:09.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul><li>现有的行人重识别研究都是基于裁剪好的行人照片来进行，而实际应用中，摄像机获取的都是全景图像，如果直接使用这样的图像去做重识别，效果会比裁剪过的输入差得多。在行人重识别中面临的光照、遮挡、背景干扰等问题也会得到放大。如果要缩小现有研究与应用之间的差距，就需要将行人检测和行人重识别结合起来，而不是作为两个单独的问题。<br><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20200809163347.png" alt=""></li></ul><h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><ul><li><p>论文提出了一种使用一个卷积神经网络联合处理行人检测和行人重识别两个子任务的深度学习框架。网络接受完整的原始图像作为输入，通过骨干网络（stem CNN）获取特征图，在特征图上使用行人提案网络（pedestrian proposal net）预测候选区域，通过RoI-Polling提取每一个区域的特征交由判别网络（identification net）判别身份。</p></li><li><p>在训练阶段，根据特征向量，使用OIM损失等一系列损失来监督判别网络的学习；在推断阶段，使用Gallery与目标行人之间的距离排序确定身份。</p></li><li><p>该框架的示意图如下：<br><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20200809145110.png" alt=""></p></li></ul><h3 id="Model-Structure"><a href="#Model-Structure" class="headerlink" title="Model Structure"></a>Model Structure</h3><ul><li><p>论文采用ResNet50作为CNN的基本架构，使用conv1至conv4_3部分作为stem CNN，经过stem CNN，会生成一张大小为原图<script type="math/tex">\frac{1}{16}</script>、维度为1024的特征图。</p></li><li><p>类似Faster R-CNN，stem CNN之后是一个<script type="math/tex">512\times 3\times 3</script>的卷积层进行一次特征的转换，随后在特征图上的每个位置通过9个anchors和1个Softmax分类器来预测行人，通过一个线性回归器进行BB回归，最后采用NMS保留128个候选框作为最终的proposals。</p></li><li><p>对于每个proposal，使用RoI Pooling从特征图里获取一个<script type="math/tex">1024\times 14\times 14</script>的特征图，将其送入ResNet后续的conv4_4至conv5_3层，通过Global Average Pooling获取2048维的特征向量。</p></li><li><p>此后，网络分成两个任务分支，其中一个分支，将特征向量投影到经过L2正则化的256维空间，计算与目标行人的余弦相似度；另一个分支考虑到pedestrian proposal net中生成的提案存在误分类或不对齐的可能性，使用Softmax分类器和线性回归器来拒绝非行人提案并修正边框。</p></li></ul><h3 id="Online-Instance-Matching-Loss"><a href="#Online-Instance-Matching-Loss" class="headerlink" title="Online Instance Matching Loss"></a>Online Instance Matching Loss</h3><ul><li><p>假定训练集中存在<script type="math/tex">L</script>个不同身份的行人，若某一proposal匹配到某一目标行人，称该proposal为labeled identity，并为其确定对应的身份；若proposal确为行人，但不是目标行人，称为unlabeled identity；对于其他的非行人proposal，称为background clutter。<br><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20200809152805.png" alt=""></p></li><li><p>类似三元损失，OIM也希望缩小相同身份的人之间的距离，增大不同身份的人之间的距离。OIM使用记忆体去存储所有任务的特征，通过在线逼近（online approximation）进行优化。具体的操作如下：</p><ul><li><p>对于labeled identity，其特征被记作<script type="math/tex">x\in \mathbb{R}^D</script>，维护一个查找表<script type="math/tex">V\in \mathbb{R}^{D\times L}</script>用于记录所有身份的特征信息，在前向传播中，通过计算<script type="math/tex">V^\top x</script>来计算样本和所有身份之间的余弦相似度；在反向传播过程中更新对应身份<script type="math/tex">t</script>对应的行<script type="math/tex">v_t\leftarrow \gamma v_t+(1-\gamma)x</script>。</p></li><li><p>对于unlabeled identity，可以视为负样本，其特征被记作<script type="math/tex">x\in \mathbb{R}^D</script>，使用一个循环队列<script type="math/tex">U\in \mathbb{R}^{D\times Q}</script>保存其特征，其中<script type="math/tex">Q</script>为队列长度。每一轮迭代过后，将新的特征向量压入队列，并剔除过期的向量。</p></li></ul></li><li><p>基于查找表和循环队列这两个记忆体，可以通过Softmax函数定义某个labeled identity的特征<script type="math/tex">x</script>属于第<script type="math/tex">i</script>个身份的概率<script type="math/tex">p_i</script>或某个unlabeled identity的特征<script type="math/tex">x</script>属于第<script type="math/tex">i</script>类unlabelled identity的概率<script type="math/tex">q_i</script>如下</p><script type="math/tex; mode=display">p_i=\frac{\exp(v_i^\top x / \tau)}{\sum_{j=1}^L \exp(v_j^\top x / \tau)+\sum_{k=1}^{Q}\exp(u_k^\top x / \tau)} \\q_i=\frac{\exp(u_i^\top x / \tau)}{\sum_{j=1}^L \exp(v_j^\top x / \tau)+\sum_{k=1}^{Q}\exp(u_k^\top x / \tau)}</script></li><li><p>OIM损失函数的优化目标是使得对数似然函数的期望最大化，即</p><script type="math/tex; mode=display">\mathcal{L}=E_x[\log p_t]\\\frac{\partial \mathcal{L}}{\partial x}=\frac{1}{\tau}[(1-p_t)v_t-\sum_{j=1,j\neq t}^Lp_jv_j-\sum_{k=1}^Qq_ku_k]</script></li></ul><h2 id="Paper-Information"><a href="#Paper-Information" class="headerlink" title="Paper Information"></a>Paper Information</h2><ul><li><p>Xiao T, Li S, Wang B, et al. Joint detection and identification feature learning for person search[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2017: 3415-3424.</p></li><li><p>Paper：<a href="https://arxiv.org/abs/1604.01850v3">https://arxiv.org/abs/1604.01850v3</a></p></li><li><p>Code：<a href="https://github.com/ShuangLI59/person_search">https://github.com/ShuangLI59/person_search</a></p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;现有的行人重识别研究都是基于裁剪好的行人照片来进</summary>
      
    
    
    
    <category term="论文笔记" scheme="http://bye-lemon.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Re-ID" scheme="http://bye-lemon.github.io/tags/Re-ID/"/>
    
    <category term="CVPR" scheme="http://bye-lemon.github.io/tags/CVPR/"/>
    
    <category term="Person Search" scheme="http://bye-lemon.github.io/tags/Person-Search/"/>
    
  </entry>
  
  <entry>
    <title>行人重识别（Person Re-identification）研究概述</title>
    <link href="http://bye-lemon.github.io/post/cde6/"/>
    <id>http://bye-lemon.github.io/post/cde6/</id>
    <published>2020-07-11T10:38:06.000Z</published>
    <updated>2021-01-17T05:45:09.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="行人重识别任务"><a href="#行人重识别任务" class="headerlink" title="行人重识别任务"></a>行人重识别任务</h2><hr><ul><li><p><strong>行人重识别（Person Re-identification，Re-ID）</strong>是一种在由<strong>多个互不重叠的摄像头</strong>组成的监控系统中<strong>判别特定行人身份</strong>的计算机视觉任务。给定一张查询图像，行人重识别系统需要在其余由多摄像机系统采集的的图像或视频序列中找出同样身份的图像。<br><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20200712093708.png" alt=""></p></li><li><p>行人重识别是一个以人为研究主体的视觉任务，类似的，以人为研究主体的视觉任务还有很多，比如<strong>检测Detection</strong>、<strong>属性Attributes</strong>、<strong>跟踪Tracking</strong>、<strong>行为识别Action Recognition</strong>、<strong>语义分割Semantic Segmentation</strong>和<strong>人脸识别Face Recognition</strong>等等。行人重识别与这些相关工作的联系紧密。</p><ul><li><p>行人检测判断图像中是否存在人物，标记出人物在图像中的位置，行人重识别的发展就是建立在行人检测之上的，如果检测给出的边界框不精准，重识别的精度也会受到很大的影响。</p></li><li><p>行人属性的信息也常常用在行人重识别的任务中，用于进行语义级查询或者单纯用于提升表征能力。</p></li><li><p>将行人重识别的结果和相机的空间位置和区域分布等信息结合起来，就能获知行人的运动轨迹，这就是<strong>多目标多机跟踪（Multi-target Multi-camera Tracking，MTMC）</strong>，事实上，Re-ID最早也是从MTMC问题中被提出来的。</p></li><li><p>类似地，人脸识别同样是判别人物身份的技术，然而由于室外监控场景常常无法获得高质量的、高分辨率的人脸图像，所以重识别在这样的场景下有着更重要的意义。<br><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20200712095906.png" alt=""></p></li></ul></li><li><p>通常，构建一个特定场景下的Re-ID系统需要经过以下五个步骤：</p><ol><li><p><strong>原始数据采集Raw Data Collection</strong></p></li><li><p><strong>生成人物边界Bounding Box Generation</strong></p></li><li><p><strong>训练数据标注Training Data Annotation</strong></p></li><li><p><strong>模型训练Model Training</strong></p></li><li><p><strong>行人检索Pedestrians Retrieval</strong></p></li></ol></li><li><p>根据上述五个步骤中的区别，Re-ID人物可以被划分为两个大类：<strong>封闭世界中的Re-ID（Closed-world）</strong>和<strong>开放世界中的Re-ID（Open-world）</strong>，两者的区别如下表所示：</p></li></ul><div class="table-container"><table><thead><tr><th style="text-align:center">Step</th><th style="text-align:center">Closed-World</th><th style="text-align:center">Open-world</th></tr></thead><tbody><tr><td style="text-align:center">原始数据采集</td><td style="text-align:center">单模态数据</td><td style="text-align:center">异构数据</td></tr><tr><td style="text-align:center">生成人物边界</td><td style="text-align:center">已完成人物的裁剪</td><td style="text-align:center">原始图像或视频</td></tr><tr><td style="text-align:center">训练数据标注</td><td style="text-align:center">充分的标注数据</td><td style="text-align:center">没有标注或难以获得标注</td></tr><tr><td style="text-align:center">模型训练</td><td style="text-align:center">能够根据正确标注顺利训练</td><td style="text-align:center">标注有噪音干扰</td></tr><tr><td style="text-align:center">行人检索</td><td style="text-align:center">查询人物一定存在于图库中</td><td style="text-align:center">开放世界</td></tr></tbody></table></div><h2 id="数据集和评估标准"><a href="#数据集和评估标准" class="headerlink" title="数据集和评估标准"></a>数据集和评估标准</h2><hr><h3 id="常见数据集"><a href="#常见数据集" class="headerlink" title="常见数据集"></a>常见数据集</h3><ul><li>PASS</li></ul><h3 id="常用评估标准"><a href="#常用评估标准" class="headerlink" title="常用评估标准"></a>常用评估标准</h3><ul><li>Re-ID任务可以看作一个检索（retrieval）任务，其返回一组带有排名的图像。因此，Re-ID任务常用的评价标准有：<strong>Rank-N</strong>、<strong>CMC</strong>、<strong>mAP</strong>等，此外也有部分使用<strong>AUC</strong>和<strong>ROC</strong>作为评估标准。</li></ul><h4 id="Top-K、CMC、Rank-N"><a href="#Top-K、CMC、Rank-N" class="headerlink" title="Top-K、CMC、Rank-N"></a>Top-K、CMC、Rank-N</h4><ul><li><p><strong>Top-K</strong>是指检索结果中置信度最高的K张图像中有正确结果的概率，即如果前K个结果中有正确的图像，Top-K就是1，否则就是0。Top-K的图像是一个单位阶跃函数，在首次出现的排名F处开始从0变成1。</p></li><li><p><strong>CMC（Cumulative Matching Characteristics，累计匹配特性）</strong>是Top-K的平均，<script type="math/tex">\text{CMC}(N)=\frac{1}{N}\sum_{n=1}^N\text{Top-K}(n)</script>，CMC曲线上的某一点代表了检索结果前几位中包含正确结果的概率。</p></li><li><p><strong>Rank-N</strong>指CMC曲线上横轴取值为N一点处的CMC值，其意义如上所述。</p></li></ul><h4 id="Precision、Recall、AP、mAP"><a href="#Precision、Recall、AP、mAP" class="headerlink" title="Precision、Recall、AP、mAP"></a>Precision、Recall、AP、mAP</h4><ul><li><p>在Re-ID任务中，对于一张待查询图像<script type="math/tex">I</script>，在图库中其同ID图像的集合为<script type="math/tex">\mathcal{I}</script>，Re-ID系统返回的查询结果的前k个的集合为<script type="math/tex">\mathcal{R}_k</script>，那么，前k位的<strong>查准率Precision@k</strong>和<strong>查全率Recall@k</strong>被定义为</p><script type="math/tex; mode=display">\text{precision@k}=\frac{|\mathcal{I}\cap \mathcal{R}_k|}{|\mathcal{R}_k|}\\\text{recall@k}=\frac{|\mathcal{I}\cap \mathcal{R}_k|}{|\mathcal{I}|}</script></li><li><p>为了更好的描述排名情况，引入了<strong>平均精度（Average Precision，AP）</strong>来评估查询结果，它是PR曲线下的面积，可以被使用以下公式计算</p><script type="math/tex; mode=display">\text{AP}=\frac{1}{2}\sum_{i=2}^{R}[(\text{recall@i}-\text{recall@i-1})(\text{precision@i}+\text{precision@i-1})]</script></li><li><p>Re-ID的mAP即是每一个Query的AP的均值。<br><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20200712112318.png" alt=""></p></li></ul><h2 id="封闭世界的Re-ID研究"><a href="#封闭世界的Re-ID研究" class="headerlink" title="封闭世界的Re-ID研究"></a>封闭世界的Re-ID研究</h2><hr><ul><li>封闭世界内的Re-ID研究大致可以分为三个方向：<strong>基于表征学习的Re-ID</strong>、<strong>基于度量学习的Re-ID</strong>和<strong>排名优化</strong>。</li></ul><h3 id="基于表征学习的Re-ID"><a href="#基于表征学习的Re-ID" class="headerlink" title="基于表征学习的Re-ID"></a>基于表征学习的Re-ID</h3><h4 id="基于全局特征的Re-ID"><a href="#基于全局特征的Re-ID" class="headerlink" title="基于全局特征的Re-ID"></a>基于全局特征的Re-ID</h4><ul><li><p>PersonNet: Person Re-identification with Deep Convolutional Neural Networks<br><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20200712115208.png" alt=""></p></li><li><p>注意力</p></li></ul><h4 id="基于局部特征的Re-ID"><a href="#基于局部特征的Re-ID" class="headerlink" title="基于局部特征的Re-ID"></a>基于局部特征的Re-ID</h4><ul><li>PASS</li></ul><h4 id="基于辅助特征的Re-ID"><a href="#基于辅助特征的Re-ID" class="headerlink" title="基于辅助特征的Re-ID"></a>基于辅助特征的Re-ID</h4><h5 id="基于语义属性的Re-ID"><a href="#基于语义属性的Re-ID" class="headerlink" title="基于语义属性的Re-ID"></a>基于语义属性的Re-ID</h5><ul><li>Improving person re-identification by attribute and identity learning<br><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20200712121518.png" alt=""></li></ul><h5 id="基于相机视角的Re-ID"><a href="#基于相机视角的Re-ID" class="headerlink" title="基于相机视角的Re-ID"></a>基于相机视角的Re-ID</h5><ul><li>[ICCV2019] View Confusion Feature Learning for Person Re-identification<br><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20200712122135.png" alt=""></li></ul><h5 id="基于域信息的Re-ID"><a href="#基于域信息的Re-ID" class="headerlink" title="基于域信息的Re-ID"></a>基于域信息的Re-ID</h5><ul><li>[CVPR2016] Learning Deep Feature Representations with Domain Guided Dropout for Person Re-identification<br><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20200712122606.png" alt=""></li></ul><h5 id="基于GAN的Re-ID"><a href="#基于GAN的Re-ID" class="headerlink" title="基于GAN的Re-ID"></a>基于GAN的Re-ID</h5><ul><li>[CVPR2018] Camera Style Adaptation for Person Re-identification<br><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20200712123323.png" alt=""></li></ul><h4 id="基于视频特征的Re-ID"><a href="#基于视频特征的Re-ID" class="headerlink" title="基于视频特征的Re-ID"></a>基于视频特征的Re-ID</h4><ul><li>[TCSVT] Video-based Person Re-identification with Accumulative Motion Context<br><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20200712123753.png" alt=""></li></ul><h3 id="基于度量学习的Re-ID"><a href="#基于度量学习的Re-ID" class="headerlink" title="基于度量学习的Re-ID"></a>基于度量学习的Re-ID</h3><h4 id="常见距离度量方式"><a href="#常见距离度量方式" class="headerlink" title="常见距离度量方式"></a>常见距离度量方式</h4><ul><li>PASS</li></ul><h4 id="常见损失函数"><a href="#常见损失函数" class="headerlink" title="常见损失函数"></a>常见损失函数</h4><ul><li><p>判别损失</p></li><li><p>验证损失</p></li><li><p>对比损失</p></li><li><p>三元损失</p></li><li><p>四元损失</p></li><li><p>Triple Hard</p></li><li><p>边界挖掘损失</p></li><li><p>OIM损失</p></li><li><p>Circle Loss</p></li></ul><h3 id="排名优化"><a href="#排名优化" class="headerlink" title="排名优化"></a>排名优化</h3><h4 id="重排名Re-ranking"><a href="#重排名Re-ranking" class="headerlink" title="重排名Re-ranking"></a>重排名Re-ranking</h4><h5 id="自适应重排名"><a href="#自适应重排名" class="headerlink" title="自适应重排名"></a>自适应重排名</h5><ul><li>[CVPR2017] Re-ranking Person Re-identification with k-reciprocal Encoding<br><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20200712125359.png" alt=""></li></ul><h5 id="基于人机交互的重排名"><a href="#基于人机交互的重排名" class="headerlink" title="基于人机交互的重排名"></a>基于人机交互的重排名</h5><ul><li>[ECCV2016] Human-In-The-Loop Person Re-Identification<br><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20200712130017.png" alt=""></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;行人重识别任务&quot;&gt;&lt;a href=&quot;#行人重识别任务&quot; class=&quot;headerlink&quot; title=&quot;行人重识别任务&quot;&gt;&lt;/a&gt;行人重识别任务&lt;/h2&gt;&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;行人重识别（Person Re-identificati</summary>
      
    
    
    
    <category term="论文笔记" scheme="http://bye-lemon.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Re-ID" scheme="http://bye-lemon.github.io/tags/Re-ID/"/>
    
  </entry>
  
  <entry>
    <title>《Transferable, Controllable, and Inconspicuous Adversarial Attacks on Person Re-identification With Deep Mis-Ranking》论文笔记</title>
    <link href="http://bye-lemon.github.io/post/7f95/"/>
    <id>http://bye-lemon.github.io/post/7f95/</id>
    <published>2020-07-07T03:04:08.000Z</published>
    <updated>2021-01-17T05:45:09.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul><li><p>伴随着深度神经网络技术的发展，Re-ID任务得到了很好的发展，然而Re-ID从深度神经网络里得到不仅仅是提升，也继承了深度神经网络中脆弱性。近年来针对深度神经网络的对抗性攻击取得了不错的成果，在图像分类等人物中，已经有很好的方案去欺诈分类器。本文希望通过对抗性攻击完成对基于DNN的Re-ID模型的欺诈。<br><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20200707143708.png" alt=""></p></li><li><p>通过探索对现有Re-ID模型的对抗性攻击，可以挖掘出现有的模型的弱点，有利于对Re-ID问题的鲁棒性的提升，是一项很有意义的工作。</p></li><li><p>由于现实世界中的人物是无穷尽的，且他们不会存在于数据集中。因此，针对Re-ID问题的攻击和对于图像分类等人物的攻击是不一样的，应被视为一个<strong>跨域黑箱攻击</strong>问题。现有的对抗性攻击方法通常都不具有跨域迁移性，同时，作者期望这样的攻击是隐式的，在不影响图像的感知质量的条件下实现攻击，使人眼不能发觉图像已经过了破坏。</p></li></ul><h2 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h2><h3 id="Overall-Framework"><a href="#Overall-Framework" class="headerlink" title="Overall Framework"></a>Overall Framework</h3><ul><li>下图展示了网络的基本框架，网络的目标是通过生成器<script type="math/tex">\mathcal{G}</script>为每一张输入图像<script type="math/tex">\mathcal{I}</script>生成一组具有欺骗性的噪音<script type="math/tex">\mathcal{P}</script>，进而获得对抗性样本<script type="math/tex">\hat{\mathcal{I}}</script>，该样本可以欺骗Re-ID系统<script type="math/tex">\mathcal{T}</script>使其输出错误的结果。<br><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20200707112322.png" alt=""></li></ul><h3 id="Learning-to-Mis-Rank-Formulation-For-ReID"><a href="#Learning-to-Mis-Rank-Formulation-For-ReID" class="headerlink" title="Learning-to-Mis-Rank Formulation For ReID"></a>Learning-to-Mis-Rank Formulation For ReID</h3><ul><li>为了打乱Re-ID系统输出的排序，论文提出了一种新的<strong>误排序损失Mis-ranking Loss</strong>来攻击Re-ID系统的排序环节。该损失的形式同三元损失类似，但优化方向与三元损失相反，误排序损失希望最小化不匹配样本对之间的距离，同时最大化匹配的样本对之间的距离。该损失函数的形式如下：</li></ul><script type="math/tex; mode=display">\mathcal{L}_{adv\_etri}=\sum_{k=1}^{K}\sum_{c=1}^{C_k}[\max_{\substack{j\ne k\\ j=1\dotso K\\ c_{d}=1\dotso C_j}}\|\mathcal{T}(\hat{\mathcal{I}_c^k})-\mathcal{T}(\hat{\mathcal{I}_{c_d}^k})\|_2^2-\mathop{\min}_{c_s=1\cdots C_k}\|\mathcal{T}(\hat{\mathcal{I}_c^k})-\mathcal{T}(\hat{\mathcal{I}_{c_s}^k})\|_2^2+\Delta]_+</script><ul><li>上式中<script type="math/tex">C_k</script>代表第<script type="math/tex">k</script>个ID下的人物图像样本的数量，<script type="math/tex">\mathcal{I}_c^k</script>代表第<script type="math/tex">k</script>个ID下的第<script type="math/tex">c</script>张图像样本，<script type="math/tex">c_s</script>和<script type="math/tex">c_d</script>代表同一个ID和不同ID下的样本，<script type="math/tex">\Delta</script>代表边界阈值。</li></ul><h3 id="Learning-Transferable-Features-for-Attacking"><a href="#Learning-Transferable-Features-for-Attacking" class="headerlink" title="Learning Transferable Features for Attacking"></a>Learning Transferable Features for Attacking</h3><ul><li><p>为了提升模型的迁移能力，论文作者设计了一种新型的判别器结构，配合ResNet50的生成器，组成了一个拥有更强的表征学习能力的GAN网络，用于提取通用性更强的特征来实施对抗干扰。</p></li><li><p>判别器<script type="math/tex">\mathcal{D}</script>使用了多尺度输入下的多层次特征进行融合，其网络结构如图所示<br><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20200707125744.png" alt=""></p></li></ul><h3 id="Controlling-the-Number-of-the-Attacked-Pixels"><a href="#Controlling-the-Number-of-the-Attacked-Pixels" class="headerlink" title="Controlling the Number of the Attacked Pixels"></a>Controlling the Number of the Attacked Pixels</h3><ul><li><p>为了使攻击不易被感知（即，使攻击可以欺骗Re-ID系统，但不易被人类察觉），作者做了两个方面的工作，其中之一是控制被攻击的像素点的个数。</p></li><li><p>本文对判别器的Softmax输出向量<script type="math/tex">\lambda_{i,j}</script>通过一个基于Gumbel-Softmax的方式计算特征图上所有像素点的概率分布，掩膜<script type="math/tex">\mathcal{M}</script>选取概率最高的<script type="math/tex">k</script>个像素点保留，其余在正向传播中舍弃，以此从生成器输出的初始噪声<script type="math/tex">\mathcal{P^\prime}</script>中选择出最终的噪声<script type="math/tex">\mathcal{P}</script>。</p><script type="math/tex; mode=display">M_{ij}=\left\{\begin{aligned}&\mathcal{KeepTopk}(p_{i,j}),& \text{in forward propagation}\\&p_{i,j},& \text{in backward propagation}\end{aligned}\right. \\p_{i,j}=\frac{\exp((\log(\lambda_{i,j}+\mathcal{N}_{i,j}))/\tau)}{\sum_{i,j=1}^{H,W}\exp((\log(\lambda_{i,j}+\mathcal{N}_{i,j}))/\tau)}</script></li><li><p>式中<script type="math/tex">\mathcal{N}_{i,j}=-\log(-\log(U)),U\thicksim Uniform(0,1)</script>，<script type="math/tex">\tau</script>是分布的软化参数。</p></li></ul><h3 id="Perception-Loss-for-Visual-Qualit"><a href="#Perception-Loss-for-Visual-Qualit" class="headerlink" title="Perception Loss for Visual Qualit"></a>Perception Loss for Visual Qualit</h3><ul><li><p>作者为了保证攻击不易察觉所做的另一个工作是引入了一个损失函数来描述所生成图像与原始图像的视觉差异。</p></li><li><p>受启发于<strong>多尺度结构相似性（Multi-Scale-Structure Similarity Index，MS-SSIM）</strong>，作者提出了感知损失（Perception Loss）<script type="math/tex">\mathcal{L}_{VP}</script>，其具体形式如下</p><script type="math/tex; mode=display">\mathcal{L}(\mathcal{I},\hat{\mathcal{L}})=[l_L(\mathcal{I},\hat{\mathcal{L}})]^{\alpha_L}\cdot \prod_{j=1}^{L}[c_j(\mathcal{I},\hat{\mathcal{L}})]^{\beta_j}[s_j(\mathcal{I},\hat{\mathcal{L}})]^{\gamma_j}\\c_j(\mathcal{I},\hat{\mathcal{L}})=\frac{2\sigma_\mathcal{I}\sigma_{\hat{\mathcal{I}}}+C_2}{\sigma_\mathcal{I}^2+\sigma_{\hat{\mathcal{I}}}^2+C_2}\\s_j(\mathcal{I},\hat{\mathcal{L}})=\frac{\sigma_{\mathcal{I}\hat{\mathcal{I}}}+C_3}{\sigma_\mathcal{I}\sigma_{\hat{\mathcal{I}}}+C_3}</script></li><li><p>上式中<script type="math/tex">\sigma</script>代表方差或协方差，<script type="math/tex">\alpha_L,\beta_j,\gamma_j</script>是各个组件的权重，<script type="math/tex">L</script>代表图像的尺度级。</p></li></ul><h3 id="Objective-Function"><a href="#Objective-Function" class="headerlink" title="Objective Function"></a>Objective Function</h3><ul><li><p>除了上文提到的误排序损失<script type="math/tex">\mathcal{L}_{adv\_etri}</script>和感知损失<script type="math/tex">\mathcal{L}_{VP}</script>，网络还受两个损失函数的监督，分别是误分类损失（Misclassification Loss）<script type="math/tex">\mathcal{L}_{adv\_xent}</script>和GAN损失<script type="math/tex">\mathcal{L}_{GAN}</script>，四种损失经过加权得到总的损失<script type="math/tex">\mathcal{L}</script>。</p><script type="math/tex; mode=display">\mathcal{L}=\mathcal{L}_{GAN}+\mathcal{L}_{adv\_xent}+\zeta\mathcal{L}_{adv\_etri}+\eta(1-\mathcal{L}_{VP})</script></li><li><p><strong>误分类损失</strong>在形式上是一个带有标签平滑的交叉熵损失，唯一的区别在于对于标签的编码形式，常规的分类任务会将标签编码成真实类别为1其余项为0的One-hot编码，这里的编码形式是使正确类别为0，其余类别为<script type="math/tex">\frac{1}{K-1}</script>，<script type="math/tex">K</script>是总的类别数。<script type="math/tex">\mathcal{S}(\cdot)</script>代表log-softmax函数，<script type="math/tex">\delta</script>是平滑因子。</p><script type="math/tex; mode=display">\mathcal{L}_{adv\_xent}=-\sum_{k=1}^{K}\mathcal{S}(\mathcal{T}(\hat{\mathcal{I}}))_k((1-\delta)\mathbf{1}_{\arg\min\mathcal{T}({\mathcal{I}}_k)}+\delta v_k)</script></li><li><p><strong>GAN损失</strong>被定义为</p><script type="math/tex; mode=display">\mathcal{L}_{GAN}=\mathbb{E}_{(I_{c_d},I_{c_s})}[\log\mathcal{D}_{1,2,3}(I_{c_d},I_{c_s})]+\mathbb{E}_{\mathcal{I}}[\log(1-\mathcal{D}_{1,2,3}(\mathcal{I},\hat{\mathcal{I}}))]</script></li></ul><h2 id="Paper-Information"><a href="#Paper-Information" class="headerlink" title="Paper Information"></a>Paper Information</h2><ul><li><p>Wang H, Wang G, Li Y, et al. Transferable, Controllable, and Inconspicuous Adversarial Attacks on Person Re-identification With Deep Mis-Ranking[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020: 342-351.</p></li><li><p>Paper：<a href="https://arxiv.org/abs/2004.04199">https://arxiv.org/abs/2004.04199</a></p></li><li><p>Code：<a href="https://github.com/whj363636/Adversarial-attack-on-Person-ReID-With-Deep-Mis-Ranking">https://github.com/whj363636/Adversarial-attack-on-Person-ReID-With-Deep-Mis-Ranking</a></p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;伴随着深度神经网络技术的发展，Re-ID任</summary>
      
    
    
    
    <category term="论文笔记" scheme="http://bye-lemon.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Re-ID" scheme="http://bye-lemon.github.io/tags/Re-ID/"/>
    
    <category term="CVPR" scheme="http://bye-lemon.github.io/tags/CVPR/"/>
    
  </entry>
  
  <entry>
    <title>《Weakly supervised discriminative feature learning with state information for person identification》论文笔记</title>
    <link href="http://bye-lemon.github.io/post/4d08/"/>
    <id>http://bye-lemon.github.io/post/4d08/</id>
    <published>2020-07-04T11:57:13.000Z</published>
    <updated>2021-01-17T05:45:09.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul><li><p>由于人工标注的代价十分高昂，对于可判别性视觉特征的无监督学习是一个非常具有吸引力的课题。不同状态（例如相机视角、人物姿势等）下同一个体的不同图像可能会有一定的差异，这样的差异为无监督学习带来了不小的挑战。</p></li><li><p>本篇论文提出了简单的伪标注模型，并提出一种使用状态信息作为弱监督条件的决策边界修正方法和特征漂移正则化方法。</p></li></ul><h2 id="Weakly-supervised-Discriminative-Learning-with-State-Information"><a href="#Weakly-supervised-Discriminative-Learning-with-State-Information" class="headerlink" title="Weakly supervised Discriminative Learning with State Information"></a>Weakly supervised Discriminative Learning with State Information</h2><h3 id="Basic-Model"><a href="#Basic-Model" class="headerlink" title="Basic Model"></a>Basic Model</h3><ul><li><p>定义<script type="math/tex">\mathcal{U}=\{u_i\}_{i=1}^N</script>代表输入的未标注数据集，<script type="math/tex">u_i</script>代表一张未标注的图像，<script type="math/tex">s_i\in \{1,\cdots,J\}</script>代表图像的状态信息，例如光照。改论文希望能够学习到一个深度神经网络<script type="math/tex">f</script>将输入图像编码到一个深度特征空间，定义特征编码为<script type="math/tex">x</script>，即<script type="math/tex">x=f(u;\theta)</script>，其中<script type="math/tex">\theta</script>代表网络的参数。</p></li><li><p>进一步的，对于每一个特征空间下的编码<script type="math/tex">x</script>，可以假定其属于一个代理类之中，这个分类任务可以由一个代理分类器<script type="math/tex">\mu</script>完成。此时，这一判别学习任务可以被视作代理分类器的分类任务。</p><script type="math/tex; mode=display">\mathop{\min}_{\theta,\{\mu_k\}}L_{surr}=-\sum_{x}\log\frac{\exp(x^\top \mu_{\hat{y}})}{\sum_{k=1}{K}\exp(x^\top \mu_k)}</script></li><li><p>上式中<script type="math/tex">\hat{y}</script>代表<script type="math/tex">x</script>所属的代理类，可以通过下式获得</p><script type="math/tex; mode=display">\hat{y}=\mathop{\arg\mathop{\max}_{k}}\exp(x^\top \mu_{k})</script></li><li><p>然而这样的代理类划分并不总是正确的，部分图像质量较差，存在失真，可能使该图像错误地跨越决策边界，被划分到其他类别，出现局部的错误；更普遍的，一些环境因素，例如低光照，可能使图像的可判别性更差，使得一批相同状态的图像同时朝同样的方向发生偏移。<br><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20200704215720.png" alt=""></p></li><li><p>针对上述问题，论文设计了以下两种策略来解决这两个问题：</p><ol><li><p><strong>弱监督条件下的决策边界修正（Weakly supervised decision boundary rectification，WDBR）</strong></p></li><li><p><strong>弱监督条件下的特征漂移正则化（Weakly supervised feature drift regularization，WFDR）</strong></p></li></ol></li></ul><h3 id="Weakly-supervised-decision-boundary-rectification"><a href="#Weakly-supervised-decision-boundary-rectification" class="headerlink" title="Weakly supervised decision boundary rectification"></a>Weakly supervised decision boundary rectification</h3><ul><li><p>WDBR基于一种朴素的思考：一般的数据集设定中，某一特定ID的人物，在不同的State下出现的图像应该是近乎均等的，如果某一代理类出现了过多某一状态下的图像样本，很可能是因为环境因素使得这一局部的决策边界未能得到合理划分。</p></li><li><p>基于这样的思考，WDBR引入了一种量化指标<strong>最大优势指数（Maximum Predominance Index，MPI）</strong>，对于第<script type="math/tex">k</script>个代理类，这一指数被定义如下</p><script type="math/tex; mode=display">R_k=\frac{\mathop{\max}_{j}|\mathcal{M}\cap\mathcal{Q}_j|}{|\mathcal{M}_k|}\in[0,1]\\\mathcal{M}_k=\{x_i|\hat{y}_i=k\}\\\mathcal{Q}_j=\{x_i|s_i=j\}</script></li><li><p>WDBR进一步定义了一个修正因子<script type="math/tex">p(k)=\frac{1}{1+\exp(a\cdot(R_k-b))}\in[0,1]</script>，其中<script type="math/tex">a</script>为修正强度系数，<script type="math/tex">b</script>为修正阈值。引入了修正因子之后，代理类的判定被调整为</p><script type="math/tex; mode=display">\hat{y}=\mathop{\arg\mathop{\max}_{k}}p(k)\exp(x^\top \mu_{k})</script></li><li><p>经过决策边界修正，修正因子也参与到了代理类的划分之中，定性分析，如果某一代理类下存在某一种状态的聚集，其MPI值会较大，<script type="math/tex">p(k)</script>值较小，这样在下一次迭代中这一代理类被选择的可能就会减小，位于决策边界的样本会更倾向于相邻的类别，经过这样的调整，两个代理类<script type="math/tex">\mu_1</script>和<script type="math/tex">\mu_2</script>的新决策边界会调整为</p><script type="math/tex; mode=display">(\mu_1-\mu_2)^\top x+\log\frac{p(1)}{p(2)}=0</script></li></ul><h3 id="Weakly-supervised-feature-drift-regularization"><a href="#Weakly-supervised-feature-drift-regularization" class="headerlink" title="Weakly supervised feature drift regularization"></a>Weakly supervised feature drift regularization</h3><ul><li><p>WFDR考虑解决那些因为环境因素所带来的普遍影响，也引入了相似的思考，一般的数据集设定中，各种不同的State下出现的图像，其ID分布应该是近似相同的。</p></li><li><p>为了消去不同环境条件对编码带来的影响，WFDR希望让不同环境条件下的图像导出的编码能拥有近似的代理类分布。定义第<script type="math/tex">j</script>类状态下的代理类分布是<script type="math/tex">\mathbb{P}(\mathcal{Q}_j)</script>，定义全局代理类分布是<script type="math/tex">\mathbb{P}(\mathcal{X})</script>，其中<script type="math/tex">\mathcal{X}=f(\mathcal{U})</script>。此时，WFDR的目标是</p><script type="math/tex; mode=display">\mathop{\min}_{\theta}L_{drift}=\sum_{j}d(\mathbb{P}(\mathcal{Q}_j),\mathbb{P}(\mathcal{X}))</script></li><li><p>式中<script type="math/tex">d(\cdot,\cdot)</script>描述了两个分布之间的距离，其具体形式是一个<strong>二维Wasserstein距离</strong>，以<script type="math/tex">m</script>和<script type="math/tex">\sigma</script>描述分布的均值和标准差，上式中的距离可被展开为</p><script type="math/tex; mode=display">d(\mathbb{P}(\mathcal{Q}_j),\mathbb{P}(\mathcal{X}))=\|m_j-m\|_2^2+\|\sigma_j-\sigma\|_2^2</script></li><li><p>WFDR的优化项是网络的参数，经过WFDR优化后，不同State下的图像样本会被编码为相似的分布，这样，因为环境因素带来的特征漂移，就会被最大程度的修正。</p></li></ul><h3 id="Loss-Fuction"><a href="#Loss-Fuction" class="headerlink" title="Loss Fuction"></a>Loss Fuction</h3><ul><li>模型的损失函数被定义为<script type="math/tex; mode=display">\mathop{\min}_{\theta,\{\mu_k\}}L=L_{surr}+\lambda L_{drift}</script></li></ul><h2 id="Paper-Information"><a href="#Paper-Information" class="headerlink" title="Paper Information"></a>Paper Information</h2><ul><li><p>Yu H X, Zheng W S. Weakly supervised discriminative feature learning with state information for person identification[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020: 5528-5538.</p></li><li><p>Paper：<a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Yu_Weakly_Supervised_Discriminative_Feature_Learning_With_State_Information_for_Person_CVPR_2020_paper.html">https://openaccess.thecvf.com/content_CVPR_2020/html/Yu_Weakly_Supervised_Discriminative_Feature_Learning_With_State_Information_for_Person_CVPR_2020_paper.html</a></p></li><li><p>Code：<a href="https://github.com/KovenYu/state-information">https://github.com/KovenYu/state-information</a></p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;由于人工标注的代价十分高昂，对于可判别性视</summary>
      
    
    
    
    <category term="论文笔记" scheme="http://bye-lemon.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Re-ID" scheme="http://bye-lemon.github.io/tags/Re-ID/"/>
    
    <category term="CVPR" scheme="http://bye-lemon.github.io/tags/CVPR/"/>
    
  </entry>
  
  <entry>
    <title>《Pose-guided Visible Part Matching for Occluded Person ReID》论文笔记</title>
    <link href="http://bye-lemon.github.io/post/8337/"/>
    <id>http://bye-lemon.github.io/post/8337/</id>
    <published>2020-07-02T07:54:46.000Z</published>
    <updated>2021-01-17T05:45:09.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul><li><p>许多Re-ID的方法都假设了行人完整的身体都是可见的，然而在真实场景下，这样的假设很难被满足，行人可能会被其他行人、树木、车辆等遮挡。因此，一种能够有效地解决有遮挡情况下的Re-ID问题的方法是被迫切需要的。</p></li><li><p>有遮挡的Re-ID任务主要有以下两个挑战：</p><ol><li><p>传统的基于全局图像监督的Re-ID方法所提取的特征不仅仅包括行人特征还包括了遮挡物的特征，而遮挡物的颜色形状等特征具有多样性，使得对于目标特征的描述难以具有很高的鲁棒性。</p></li><li><p>有些时候，被遮挡的部分包含了更多的有判别性的特征而未被遮挡部分在数据集中趋向同质，这会导致错误匹配的问题。</p></li></ol></li><li><p>一种直观的解决思路是检测未被遮挡的部分，使用这一部分去匹配。然而由于标注中没有遮挡部分和未遮挡部分的信息，现有的方法只能借助一些在其他数据源上进行的身体分割、姿态估计等任务来完成。但是这样的方法有着巨大的跨域数据偏差问题，不能保证其他数据源上的模型能够在当前数据集下有良好的效果。</p></li><li><p>这篇论文提出了一种<strong>姿态导向的可见部位匹配（Pose-guided Visible Part Matching，PVPM）网络</strong>，通过自主学习的方式直接对图像的可见性进行打分。PVPM包括两个主要的组件<strong>姿态导向的部件注意力（Pose-guided Part Attention，PGA）</strong>和<strong>姿态导向的可见性预测器（Pose-guided Visibility Predictor，PVP）</strong>。PVP的训练过程受一组伪标注监督，这一伪标注通过使用图匹配方法求解一个特征对应问题得到。最终两张图像的匹配得分通过将各个部件的距离按照其可见性得分加权聚合得到。</p></li></ul><h2 id="Pose-Guide-Visible-Part-Matching"><a href="#Pose-Guide-Visible-Part-Matching" class="headerlink" title="Pose-Guide Visible Part Matching"></a>Pose-Guide Visible Part Matching</h2><ul><li>PVPM网络的流水线和训练过程如下图所示：<br><img src="https://raw.githubusercontent.com/Bye-lemon/Pictures/master/20200702164556.png" alt=""></li></ul><h3 id="Part-Features-with-Pose-Guide-Attention"><a href="#Part-Features-with-Pose-Guide-Attention" class="headerlink" title="Part Features with Pose-Guide Attention"></a>Part Features with Pose-Guide Attention</h3><ul><li><p>在有所遮挡的情形下，有判别性的部件会显得尤其重要，为了实现这样的区分，PVPM将身体上各个部件的特征通过一个由姿态导向的注意力加权融合。</p></li><li><p>对于一张给定的图像<script type="math/tex">I</script>，首先通过一个卷积神经网络提取其外观特征图<script type="math/tex">F\in \mathbb{R}^{C\times H\times W}</script>，接下来通过姿态估计器、姿态编码器和注意力生成器输出一组姿态注意力。</p><ul><li><p>在姿态估计这一过程，PVPM使用了OpenPose方法，OpenPose输出一组关键点热力图<script type="math/tex">K</script>和部件亲和力场<script type="math/tex">L_p</script>；</p></li><li><p>随后，PVPM通过一个姿态编码器将<script type="math/tex">P=K\oplus L_p</script>作为输入嵌入到高阶姿态特征<script type="math/tex">F_{pose}</script>中，这一过程可以被描述为<script type="math/tex">F_{pose}=PE(P;\theta_e)</script>，其中<script type="math/tex">\theta_e</script>代表编码器的参数；</p></li><li><p>此后，注意力生成器通过一个<script type="math/tex">1\times 1</script>卷积和紧随其后的Sigmoid函数，生成一组2维堆叠注意力图<script type="math/tex">A</script>，这一过程可被描述为<script type="math/tex">A=PGA(F_{pose};\theta_a)\in \mathcal{R}^{N_p\times H\times W}</script>。</p></li></ul></li><li><p>注意力图<script type="math/tex">A</script>上的每一个元素<script type="math/tex">a_i^{h,w}</script>代表着特征图<script type="math/tex">F</script>上的点<script type="math/tex">(h,w)</script>属于第<script type="math/tex">i</script>个部件的度。由于理想情况下各个部件的覆盖区域应该是不重叠且彼此互补的，PVPM通过提取每一个部件特征图上值最大的部分的空间位置，来重新生成了每个部件的注意力图<script type="math/tex">\bar{A}</script>。即</p><script type="math/tex; mode=display">\bar{A}_i=A_i\circ [\mathop{\arg\max}_{i}  A_i]|_{onehot}^C</script></li><li><p>最后，每一个部件的特征<script type="math/tex">f_i</script>可以通过对特征图上的各个部件的加权池化来获得</p><script type="math/tex; mode=display">f_i=\frac{1}{\|\bar{A}_i\|}\sum_{h=1}^{H}\sum_{w=1}^{W}\bar{a}_i^{h,w}\circ F^{h,w}\\\|\bar{A}_i\|=\sum_{h=1}^{H}\sum_{w=1}^{W}\bar{a}_i^{h,w}</script></li></ul><h3 id="Pose-Guide-Visibility-Prediction"><a href="#Pose-Guide-Visibility-Prediction" class="headerlink" title="Pose-Guide Visibility Prediction"></a>Pose-Guide Visibility Prediction</h3><ul><li><p>在对人体提取了基于部件的特征之后，对于特征间距离的度量自然需要做部件与部件之间的度量，然而并不是所有的部件在两幅图像中都存在，这时就需要一个预测器来预测部件的可见性。</p></li><li><p>PVPM通过一个包含了全局平均池化、<script type="math/tex">1\times 1</script>卷积、批归一化和Sigmoid四层的小型网络来预测各部件的可见性，这一过程可被描述为<script type="math/tex">\hat{v}=PVP(F_{pose};\theta_v)\in \mathcal{R}^{N_p}</script>。</p></li><li><p>在这样的前提下，若<script type="math/tex">d_i</script>代表第<script type="math/tex">i</script>个部件特征间的余弦距离，probe图像和gallery图像之间的距离可以被描述为</p><script type="math/tex; mode=display">d=\frac{\sum_{i=1}^{N_p}\hat{v}_i^p\hat{v}_i^qd_i}{\sum_{i=1}^{N_p}\hat{v}_i^p\hat{v}_i^q}</script></li></ul><h3 id="Pseudo-Label-Estimation-by-Graph-Matching"><a href="#Pseudo-Label-Estimation-by-Graph-Matching" class="headerlink" title="Pseudo-Label Estimation by Graph Matching"></a>Pseudo-Label Estimation by Graph Matching</h3><ul><li><p>由于在Ground Truth中各个部件的可见性一般是不能直接得到的，论文作者提出了一种自监督的可见部件检索方法。该方法基于两点前提：</p><ol><li><p>只有当某一部件同时在<script type="math/tex">I^p,I^g</script>中均可见时，该部件对的相关性才会变高。</p></li><li><p>在同一幅图中有边连接的两个部件之间也呈现高度相关性。</p></li></ol></li><li><p>基于上述考虑，PVPM希望通过估计一个描述两个部件的可见性向量的内积矩阵来估计这一相关性。</p></li><li><p>对于给定的正样本对，通过两张图<script type="math/tex">\mathcal{G}^p=(\mathcal{V}^p,\mathcal{E}^p)</script>和<script type="math/tex">\mathcal{G}^g=(\mathcal{V}^g,\mathcal{E}^g)</script>来描述，其中的元素<script type="math/tex">\mathcal{V}_i</script>和<script type="math/tex">\mathcal{E}_{i,j}</script>分别代表部件节点上的特征<script type="math/tex">f_i</script>和连接部件的边上的特征<script type="math/tex">\{f_i-f_j\}</script>。</p></li><li><p>定义二值指示向量<script type="math/tex">c\in \{0,1\}^{N_p}</script>代表<script type="math/tex">\mathcal{G}^p</script>和<script type="math/tex">\mathcal{G}^g</script>之间的匹配度，如果第<script type="math/tex">i</script>个部件同时在两张图上出现<script type="math/tex">v_i</script>将被设为1，否则为0。</p></li><li><p>定义亲和力矩阵<script type="math/tex">M</script>如下，其中<script type="math/tex">\hat{M}_{i,j}</script>代表<script type="math/tex">M_{i,j}</script>的滑动平均值：</p><script type="math/tex; mode=display">M_{i,i}=\langle \mathcal{V}_i^p,\mathcal{V}_i^g \rangle\\M_{i,j}=\langle \frac{\mathcal{E}_{i,j}^p}{\|\mathcal{E}_{i,j}^p\|_2},\frac{\mathcal{E}_{i,j}^g}{\|\mathcal{E}_{i,j}^g\|_2} \rangle - \hat{M}_{i,j}</script></li><li><p>此时，图匹配问题可以被视作一个整数二次规划问题和一个正则化项，式中<script type="math/tex">\hat{M}_{diag}</script>代表矩阵<script type="math/tex">M</script>的对角线上元素的滑动平均值：</p><script type="math/tex; mode=display">\mathop{\arg\max}_{v} v^\top Mv-\bar{\lambda}^\top v\ \mathrm{s.t.}\ v\in\{0,1\}^{N_p}\\\bar{\lambda}=\lambda\hat{M}_{diag}</script></li><li><p>通过对上述表达式的最优化，可以得到一个向量<script type="math/tex">v^*</script>，该向量指示着哪些部件在两幅图间是匹配的，这个向量将被用于优化PVP模块。</p></li></ul><h3 id="Loss-Function"><a href="#Loss-Function" class="headerlink" title="Loss Function"></a>Loss Function</h3><ul><li>PVPM的损失函数一共分为三个部分，可见性部位的预测损失<script type="math/tex">L_v</script>，部件匹配的损失<script type="math/tex">L_m</script>和识别损失<script type="math/tex">L_c</script>，即<script type="math/tex">L=L_m+L_c+L_v</script>，其中<script type="math/tex; mode=display">L_v=-\sum_{i=1}^{N_p}v_i^*\log(\hat{v}_i^p\hat{v}_i^g) \\L_m=-v^{*\top}Mv^*+\lambda^{\prime\top}v^* \\L_c=\sum_{i=1}^{N_p}\mathrm{cross-entropy}(\hat{y}_i,y_i) \\\lambda_i^\prime=\frac{\sum_{j=1,j\neq i}^{N_p}S_{ij}^p+S_{ij}^g}{2(N_p-1)}</script></li></ul><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><ul><li>此论文提出了一种姿态导向的可视化部件匹配方法来解决有遮挡的Re-ID问题。PVPM通过一个统一的框架来考虑姿态导向的注意力和部件可见性。与其他方法不同的是，PVPM不是从其他数据源来获得可见性信息，而是通过一种基于图匹配的方法自监督学习。</li></ul><h2 id="Paper-Information"><a href="#Paper-Information" class="headerlink" title="Paper Information"></a>Paper Information</h2><ul><li><p>Gao S, Wang J, Lu H, et al. Pose-guided Visible Part Matching for Occluded Person ReID[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020: 11744-11752.</p></li><li><p>Paper：<a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Gao_Pose-Guided_Visible_Part_Matching_for_Occluded_Person_ReID_CVPR_2020_paper.pdf">https://openaccess.thecvf.com/content_CVPR_2020/papers/Gao_Pose-Guided_Visible_Part_Matching_for_Occluded_Person_ReID_CVPR_2020_paper.pdf</a></p></li><li><p>Code：<a href="https://github.com/hh23333/PVPM">https://github.com/hh23333/PVPM</a></p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;许多Re-ID的方法都假设了行人完整的身体</summary>
      
    
    
    
    <category term="论文笔记" scheme="http://bye-lemon.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Re-ID" scheme="http://bye-lemon.github.io/tags/Re-ID/"/>
    
    <category term="CVPR" scheme="http://bye-lemon.github.io/tags/CVPR/"/>
    
  </entry>
  
</feed>
