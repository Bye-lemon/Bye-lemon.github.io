---
title: 《并行程序设计导论》读书笔记
tags:
  - 并行程序设计
categories: 读书笔记
abstract: 计算机科学丛书 【美】Peter S.Pacheco 著  邓倩妮等译
mathjax: true
abbrlink: e9de
date: 2019-12-02 17:21:02
---
## 为什么要并行计算
---

- 现阶段人类关注的问题，如气候模拟、蛋白质折叠、药物发现、能源研究、数据分析以及其他一些问题的解决需要强大的运算能力的支持。

- 单处理器性能不断提升的之一主要原因是**日益增加的晶体管密度**，然而增加晶体管密度会带来**能耗的增加**，进而带来散热问题。因此集成电路生产商选择通过**并行**的方法继续提升晶体管的密度，具体的方式是：与其构建更快、更复杂的单处理器，不如在单个芯片上放置多个相对简单的处理器，这样的集成电路成为**多核处理器**。

- 大多数为传统单核处理器编写的程序无法利用多核处理器，这就需要将**串行程序**改造为**并行程序**，这样才能充分的利用多核。

- 一个串行程序的高效并行实现可能不是通过发掘其中每一个步骤的高效并行实现的，最好的并行化实现可能是通过一步步回溯，然后发现一个全新的算法来获得。

- **并行化**的基本思想是将要完成的任务**分配**给各个核，两种广泛采用的方法是**任务并行**和**数据并行**。**任务并行**是指将待解决问题所需要执行的各个任务分配到各个核上执行；**数据并行**是指将待解决问题所需要处理的数据分配到各个核，每个核在分配到的数据集上执行大致相似的操作。
    
- 在编写并行化程序时，我们需要做好各个核之间的**协调**，包括**通信**、**负载平衡**和**同步**。

- 使用C语言开发**显式**并行的程序一般可以使用三种拓展：**消息传递接口（Message-Passing Interface, MPI）**、**POSIX线程（POSIX threads, Pthreads）**和**OpenMP**。其中。**MPI**是为**分布式内存系统**的编程设计的，提供发送消息的机制；**Pthreads**和**OpenMP**是为**共享内存系统**的编程而设计的，提供访问共享内存的机制。

- **并发计算（cocurrent computing）**、**并行计算（parallel computing）**和**分布式计算（distributed computing）**的区别：

    - 在**并发运算**中，一个程序的多个任务在同一时间段内可以**同时执行**；
    
    - 在**并行计算**中，一个程序通过多个任务**紧密协作**来解决某个问题；
    
    - 在**分布式计算**中，一个程序需要与其他程序协作来解决某个问题。

- 并行程序和分布式程序都是并发的，但二者之间并没有明确的界限，只是在并行程序中，多个任务一般是**紧耦合**的。

- 并行程序一般比较复杂的，因此，所有设计和开发并行程序的原则都远比开发串行程序的原则重要。

## 并行硬件和并行软件
---
### 串行硬件和串行软件
#### 冯·诺伊曼结构

- “经典”的**冯·诺伊曼结构**包括**主存**、**中央处理单元**处理器或核，以及主存和CPU之间的**互连结构**。互联结构限定了指令和数据访问的速率，因此我们将主存和CPU之间的分离称为**冯·诺伊曼瓶颈**。